{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **B∆∞·ªõc 1:** Mount Drive v√† Khai b√°o c√°c ƒë∆∞·ªùng d·∫´n"],"metadata":{"id":"dmIxkfqTG5_w"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODg49OX-tRMK","outputId":"85e100e9-4ee9-46d4-df64-fa5e8d7c41eb","collapsed":true,"executionInfo":{"status":"ok","timestamp":1766431927346,"user_tz":-420,"elapsed":146,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec 22 19:32:07 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["from google.colab import drive\n","import os, shutil\n","\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')"]},{"cell_type":"code","source":["DATASET_NAME = \"carla_128\"\n","ZIP_FILE = f\"{DATASET_NAME}.zip\"\n","DRIVE_PATH = f\"/content/drive/MyDrive/HyperNeRFGAN/data/{ZIP_FILE}\"\n","LOCAL_PATH = f\"/content/{ZIP_FILE}\""],"metadata":{"id":"hVjQhNEDKk0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 2:** Copy dataset xu·ªëng Local (ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω)\n"],"metadata":{"id":"vEhfn8UDHErI"}},{"cell_type":"code","source":["if os.path.exists(DRIVE_PATH):\n","    print(f\"üîÑ ƒêang copy {ZIP_FILE} t·ª´ Drive xu·ªëng Local...\")\n","    shutil.copy(DRIVE_PATH, LOCAL_PATH)\n","    print(f\"‚úÖ ƒê√£ copy xong: {LOCAL_PATH}\")\n","else:\n","    raise FileNotFoundError(f\"‚ùå Kh√¥ng t√¨m th·∫•y file: {DRIVE_PATH}. H√£y ki·ªÉm tra l·∫°i folder data tr√™n Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3yWDXnt5s8V","outputId":"57e15a14-cbee-4ccc-d142-7d835f5b9a44","executionInfo":{"status":"ok","timestamp":1766431927829,"user_tz":-420,"elapsed":482,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ ƒêang copy carla_128.zip t·ª´ Drive xu·ªëng Local...\n","‚úÖ ƒê√£ copy xong: /content/carla_128.zip\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 3:** C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Micromamba"],"metadata":{"id":"ep5UCTRXHxD5"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/HyperNeRFGAN\n","\n","# C√†i Micromamba\n","!mkdir -p bin\n","!curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n","!chmod +x bin/micromamba\n","\n","# T·∫°o file environment t·ªëi ∆∞u cho Colab\n","import yaml\n","env_in = \"environment.yaml\"\n","env_out = \"environment_colab.yaml\"\n","\n","# Load environment g·ªëc v√† l·ªçc b·ªè imageio-ffmpeg (c√†i pip sau)\n","if os.path.exists(env_in):\n","    y = yaml.safe_load(open(env_in, \"r\"))\n","    y[\"channels\"] = [\"conda-forge\", \"defaults\"] # B·ªè pytorch channel ƒë·ªÉ c√†i th·ªß c√¥ng\n","    deps = []\n","    for d in y.get(\"dependencies\", []):\n","        if isinstance(d, str) and (d.startswith(\"imageio-ffmpeg\") or d.startswith(\"pytorch\") or d.startswith(\"torchvision\")):\n","            continue\n","        deps.append(d)\n","    y[\"dependencies\"] = deps\n","    with open(env_out, \"w\") as f:\n","        yaml.safe_dump(y, f, sort_keys=False)\n","else:\n","    with open(env_out, \"w\") as f:\n","        f.write(\"channels:\\n  - conda-forge\\ndependencies:\\n  - python=3.8\\n  - pip\\n\")\n","\n","print(\"‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng:\", env_out)\n","\n","# T·∫°o m√¥i tr∆∞·ªùng\n","ENV_PREFIX = \"/content/hypernerfgan_env\"\n","!rm -rf {ENV_PREFIX}\n","!./bin/micromamba create -y -p {ENV_PREFIX} -f environment_colab.yaml\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H0_0P8E15xzF","outputId":"055d695d-ffa4-4d73-c0c7-0c7f10a64f27","executionInfo":{"status":"ok","timestamp":1766431972763,"user_tz":-420,"elapsed":44932,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HyperNeRFGAN\n","bin/micromamba\n","‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng: environment_colab.yaml\n","conda-forge/linux-64                                        Using cache\n","conda-forge/noarch                                          Using cache\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m Please make sure you understand Anaconda Terms of Services.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m See: https://legal.anaconda.com/policies/en/\n","\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n","\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n","pkgs/main/noarch  ‚£æ  \n","pkgs/r/linux-64   ‚£æ  \n","pkgs/r/noarch     ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n","\n","Transaction\n","\n","  Prefix: /content/hypernerfgan_env\n","\n","  Updating specs:\n","\n","   - python=3.8.5\n","   - pip=20.3\n","   - cudatoolkit=10.2\n","   - imageio\n","   - protobuf=3.20.1\n","   - pip\n","\n","\n","  Package                Version  Build                 Channel           Size\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","  Install:\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu                 conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ca-certificates \u001b[0m  2025.11.12  hbd8a1cb_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ cudatoolkit     \u001b[0m     10.2.89  hdec6ad0_13           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ freetype        \u001b[0m      2.12.1  h267a509_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ imageio         \u001b[0m      2.36.0  pyh12aca89_1          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lcms2           \u001b[0m        2.16  hb7c19ff_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.45  bootstrap_ha15bf96_4  conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lerc            \u001b[0m       4.0.0  h0aef613_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libblas         \u001b[0m      3.11.0  5_h4a7cf45_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libcblas        \u001b[0m      3.11.0  5_h0358290_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libdeflate      \u001b[0m        1.20  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libffi          \u001b[0m       3.2.1  he1b5a44_1007         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc          \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc-ng       \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran     \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran5    \u001b[0m      15.2.0  h68bc16d_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgomp         \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libjpeg-turbo   \u001b[0m       3.1.2  hb03c661_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblapack       \u001b[0m      3.11.0  5_h47877c9_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma         \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma-devel   \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libopenblas     \u001b[0m      0.3.30  pthreads_h94d23a6_4   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libpng          \u001b[0m      1.6.43  h2797004_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libprotobuf     \u001b[0m      3.20.1  h6239696_4            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libsqlite       \u001b[0m      3.46.0  hde9e2c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx       \u001b[0m      15.2.0  h934c35e_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx-ng    \u001b[0m      15.2.0  hdf11a46_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libtiff         \u001b[0m       4.6.0  h1dd3fc0_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libwebp-base    \u001b[0m       1.6.0  hd42ef1d_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libxcb          \u001b[0m        1.15  h0b41bf4_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libzlib         \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ncurses         \u001b[0m         6.5  h2d0b736_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ numpy           \u001b[0m      1.24.4  py38h59b608b_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openjpeg        \u001b[0m       2.5.2  h488ebb8_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openssl         \u001b[0m      1.1.1w  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pillow          \u001b[0m      10.3.0  py38h9e66945_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pip             \u001b[0m      20.3.4  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ protobuf        \u001b[0m      3.20.1  py38hfa26641_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pthread-stubs   \u001b[0m         0.4  hb9d3cd8_1002         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python          \u001b[0m       3.8.5  h1103e12_9_cpython    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python_abi      \u001b[0m         3.8  8_cp38                conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ readline        \u001b[0m         8.3  h853b02a_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ setuptools      \u001b[0m      75.3.0  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ six             \u001b[0m      1.16.0  pyh6c4a22f_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ sqlite          \u001b[0m      3.46.0  h6d4b2fc_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_h4845f30_101    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxau     \u001b[0m      1.0.12  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxdmcp   \u001b[0m       1.1.5  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz              \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-gpl-tools    \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-tools        \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zlib            \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zstd            \u001b[0m       1.5.6  ha6fb4c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","\n","  Summary:\n","\n","  Install: 55 packages\n","\n","  Total download: 0 B\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","\n","Transaction starting\n","\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n","\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking python_abi-3.8-8_cp38\n","Linking ca-certificates-2025.11.12-hbd8a1cb_0\n","Linking libgomp-15.2.0-he0feb66_16\n","Linking _libgcc_mutex-0.1-conda_forge\n","Linking ld_impl_linux-64-2.45-bootstrap_ha15bf96_4\n","Linking _openmp_mutex-4.5-2_gnu\n","Linking libgcc-15.2.0-he0feb66_16\n","Linking libgfortran5-15.2.0-h68bc16d_16\n","Linking ncurses-6.5-h2d0b736_3\n","Linking libjpeg-turbo-3.1.2-hb03c661_0\n","Linking xorg-libxdmcp-1.1.5-hb03c661_1\n","Linking xorg-libxau-1.0.12-hb03c661_1\n","Linking pthread-stubs-0.4-hb9d3cd8_1002\n","Linking libwebp-base-1.6.0-hd42ef1d_0\n","Linking libstdcxx-15.2.0-h934c35e_16\n","Linking libgcc-ng-15.2.0-h69a702a_16\n","Linking liblzma-5.8.1-hb9d3cd8_2\n","Linking libgfortran-15.2.0-h69a702a_16\n","Linking readline-8.3-h853b02a_0\n","Linking lerc-4.0.0-h0aef613_1\n","Linking libstdcxx-ng-15.2.0-hdf11a46_16\n","Linking openssl-1.1.1w-hd590300_0\n","Linking libxcb-1.15-h0b41bf4_0\n","Linking libdeflate-1.20-hd590300_0\n","Linking libzlib-1.2.13-h4ab18f5_6\n","Linking xz-tools-5.8.1-hb9d3cd8_2\n","Linking xz-gpl-tools-5.8.1-hbcc6ac9_2\n","Linking liblzma-devel-5.8.1-hb9d3cd8_2\n","Linking libopenblas-0.3.30-pthreads_h94d23a6_4\n","Linking libffi-3.2.1-he1b5a44_1007\n","Linking cudatoolkit-10.2.89-hdec6ad0_13\n","By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n","\n","Linking libsqlite-3.46.0-hde9e2c9_0\n","Linking zstd-1.5.6-ha6fb4c9_0\n","Linking libpng-1.6.43-h2797004_0\n","Linking tk-8.6.13-noxft_h4845f30_101\n","Linking libprotobuf-3.20.1-h6239696_4\n","Linking zlib-1.2.13-h4ab18f5_6\n","Linking xz-5.8.1-hbcc6ac9_2\n","Linking libblas-3.11.0-5_h4a7cf45_openblas\n","Linking sqlite-3.46.0-h6d4b2fc_0\n","Linking freetype-2.12.1-h267a509_2\n","Linking libtiff-4.6.0-h1dd3fc0_3\n","Linking libcblas-3.11.0-5_h0358290_openblas\n","Linking liblapack-3.11.0-5_h47877c9_openblas\n","Linking python-3.8.5-h1103e12_9_cpython\n","Linking lcms2-2.16-hb7c19ff_0\n","Linking openjpeg-2.5.2-h488ebb8_0\n","Linking wheel-0.45.1-pyhd8ed1ab_0\n","Linking setuptools-75.3.0-pyhd8ed1ab_0\n","Linking pip-20.3.4-pyhd8ed1ab_0\n","Linking six-1.16.0-pyh6c4a22f_0\n","Linking pillow-10.3.0-py38h9e66945_0\n","Linking numpy-1.24.4-py38h59b608b_0\n","Linking protobuf-3.20.1-py38hfa26641_0\n","Linking imageio-2.36.0-pyh12aca89_1\n","\n","Transaction finished\n","\n","\n","To activate this environment, use:\n","\n","    micromamba activate /content/hypernerfgan_env\n","\n","Or to execute a single command in this environment, use:\n","\n","    micromamba run -p /content/hypernerfgan_env mycommand\n","\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m You are using 'pip' as an additional package manager.\n","    Be aware that packages installed with 'pip' are managed independently from 'conda-forge' channel.\n","\u001b[36m\n","Installing pip packages: hydra-core==1.0.6, click==7.1.2, scipy==1.6.1, ninja==1.10.0, tensorboard==2.4.1, tqdm==4.59.0, gitpython, gpustat, opencv-python, -e .\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 4:** C√†i ƒë·∫∑t Pytorch v√† Dependencies"],"metadata":{"id":"ADOxSyjKIQC9"}},{"cell_type":"code","source":["print(\"‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\")\n","\n","# 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","  --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# 2. C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈© (Quan tr·ªçng)\n","# (Pip 23.3.1 ƒë·ªÉ fix l·ªói omegaconf, Setuptools<59.6 ƒë·ªÉ fix l·ªói distutils)\n","!./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","!./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# 4. C√†i Hydra & Dependencies\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# 5. C√†i c√°c util kh√°c\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja\n","\n","print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n","\n","\n","# # 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","#   --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# # 2. QUAN TR·ªåNG: C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈©\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# # 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# # 4. C√†i Hydra & Dependencies\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# # 5. C√†i c√°c util kh√°c V√Ä CH·ªêT NUMPY 1.23.5\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja \"numpy==1.23.5\"\n","\n","# print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXOuH6435y1i","outputId":"524653e1-b71a-440d-ec02-7ac77b38ca41","collapsed":true,"executionInfo":{"status":"ok","timestamp":1766432099304,"user_tz":-420,"elapsed":126536,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\n","Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.10.0+cu113\n","  Using cached https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n","Collecting torchvision==0.11.0+cu113\n","  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (21.8 MB)\n","Requirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from torch==1.10.0+cu113) (4.13.2)\n","Requirement already satisfied: numpy in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (1.24.4)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (10.3.0)\n","Installing collected packages: torch, torchvision\n","Successfully installed torch-1.10.0+cu113 torchvision-0.11.0+cu113\n","Collecting pip==23.3.1\n","  Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n","Collecting setuptools<59.6.0\n","  Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n","Requirement already satisfied: wheel in /content/hypernerfgan_env/lib/python3.8/site-packages (0.45.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.3.0\n","    Uninstalling setuptools-75.3.0:\n","      Successfully uninstalled setuptools-75.3.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.3.4\n","    Uninstalling pip-20.3.4:\n","      Successfully uninstalled pip-20.3.4\n","Successfully installed pip-23.3.1 setuptools-59.5.0\n","Obtaining file:///content/drive/MyDrive/HyperNeRFGAN\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: inr-gan\n","  Attempting uninstall: inr-gan\n","    Found existing installation: inr_gan 0.0.1\n","    Uninstalling inr_gan-0.0.1:\n","      Successfully uninstalled inr_gan-0.0.1\n","  Running setup.py develop for inr-gan\n","Successfully installed inr-gan-0.0.1\n","Requirement already satisfied: hydra-core==1.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (1.0.6)\n","Requirement already satisfied: omegaconf==2.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (2.0.6)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (4.8)\n","Requirement already satisfied: importlib-resources in /content/hypernerfgan_env/lib/python3.8/site-packages (from hydra-core==1.0.6) (6.4.5)\n","Requirement already satisfied: PyYAML>=5.1.* in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (6.0.3)\n","Requirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (4.13.2)\n","Requirement already satisfied: zipp>=3.1.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-resources->hydra-core==1.0.6) (3.20.2)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mCollecting imageio-ffmpeg\n","  Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: opencv-python in /content/hypernerfgan_env/lib/python3.8/site-packages (4.12.0.88)\n","Requirement already satisfied: tensorboard in /content/hypernerfgan_env/lib/python3.8/site-packages (2.4.1)\n","Requirement already satisfied: tqdm in /content/hypernerfgan_env/lib/python3.8/site-packages (4.59.0)\n","Requirement already satisfied: gpustat in /content/hypernerfgan_env/lib/python3.8/site-packages (1.1.1)\n","Requirement already satisfied: gitpython in /content/hypernerfgan_env/lib/python3.8/site-packages (3.1.45)\n","Requirement already satisfied: ninja in /content/hypernerfgan_env/lib/python3.8/site-packages (1.10.0)\n","Requirement already satisfied: setuptools in /content/hypernerfgan_env/lib/python3.8/site-packages (from imageio-ffmpeg) (59.5.0)\n","Requirement already satisfied: numpy<2.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n","Requirement already satisfied: absl-py>=0.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.3.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.70.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf>=3.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.20.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.32.4)\n","Requirement already satisfied: six>=1.10.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n","Requirement already satisfied: wheel>=0.26 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.45.1)\n","Requirement already satisfied: nvidia-ml-py>=11.450.129 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (13.590.44)\n","Requirement already satisfied: psutil>=5.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (7.1.3)\n","Requirement already satisfied: blessed>=1.17.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (1.25.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.0.12)\n","Requirement already satisfied: typing-extensions>=3.10.0.2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.13.2)\n","Requirement already satisfied: wcwidth>=0.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat) (0.2.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2.0.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2025.11.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard) (2.1.5)\n","Requirement already satisfied: zipp>=3.20 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.20.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.3.1)\n","Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.5.1\n","‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 5:** Patch config cho `main.yml`"],"metadata":{"id":"s9fZ1nW1Igxm"}},{"cell_type":"code","source":["main_cfg = \"configs/main.yml\"\n","import re\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch configs/main.yml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7HN8u1V53hJ","outputId":"6c2e57f1-c3b4-4b69-c541-116fdadacaeb","executionInfo":{"status":"ok","timestamp":1766432099830,"user_tz":-420,"elapsed":519,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ patch configs/main.yml\n","‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong configs/nerf-gan-carla.yml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 6:** Memory fix ·ª©ng v·ªõi t·ª´ng file `<dataset>.yml`"],"metadata":{"id":"pn580tAGIrYT"}},{"cell_type":"code","source":["# Fix OOM cho T4 GPU\n","carla_cfg = \"configs/nerf-gan-carla.yml\"\n","if os.path.exists(carla_cfg):\n","    c = open(carla_cfg,\"r\").read()\n","    # Gi·∫£m t·ª´ 64 xu·ªëng 32 ho·∫∑c 48 ƒë·ªÉ tr√°nh tr√†n VRAM\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 32\")\n","    open(carla_cfg,\"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong {carla_cfg}\")"],"metadata":{"id":"p77GNx76IyOG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 7:** X·ª≠ l√Ω ƒë·ªìng lo·∫°t c√°i file `*.yml` chu·∫©n b·ªã cho training"],"metadata":{"id":"aPJz9KxfI9fu"}},{"cell_type":"code","source":["import glob\n","import os\n","import re\n","\n","CONFIG_DIR = \"configs\"\n","config_dir = \"/content/drive/MyDrive/HyperNeRFGAN/configs\"\n","\n","# L·∫•y t·∫•t c·∫£ file trong folder configs\n","files = os.listdir(config_dir)\n","\n","for f in files:\n","    full_path = os.path.join(config_dir, f)\n","\n","    # N·∫øu l√† .yaml -> copy th√™m b·∫£n .yml\n","    if f.endswith(\".yaml\"):\n","        target = full_path.replace(\".yaml\", \".yml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","    # N·∫øu l√† .yml -> copy th√™m b·∫£n .yaml\n","    elif f.endswith(\".yml\"):\n","        target = full_path.replace(\".yml\", \".yaml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","print(\"‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\")\n","\n","# 2. Patch file main.yaml (Set 1 GPU)\n","main_cfg = os.path.join(CONFIG_DIR, \"main.yaml\")\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    # Force 1 GPU\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    # S·ª≠a tham chi·∫øu ƒë·∫øn file config con (c≈©ng ph·∫£i ƒë·ªïi th√†nh yaml n·∫øu c√≥ hardcode)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\")\n","\n","# 3. Patch file dataset config (Fix OOM cho T4 GPU)\n","# T·ª± ƒë·ªông t√¨m file config t∆∞∆°ng ·ª©ng v·ªõi DATASET_NAME\n","target_cfg_name = f\"nerf-gan-{DATASET_NAME.split('_')[0]}\" # Vd: carla_128 -> nerf-gan-carla\n","dataset_cfg = os.path.join(CONFIG_DIR, f\"{target_cfg_name}.yaml\")\n","\n","if os.path.exists(dataset_cfg):\n","    c = open(dataset_cfg, \"r\").read()\n","    # Gi·∫£m th√¥ng s·ªë ƒë·ªÉ v·ª´a v·ªõi 16GB VRAM c·ªßa T4\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 32\") # Gi·∫£m b·ªõt s·ªë m·∫´u tr√™n tia\n","    open(dataset_cfg, \"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong {dataset_cfg}\")\n","else:\n","    print(f\"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y config {dataset_cfg}. C√≥ th·ªÉ t√™n dataset kh√°c v·ªõi quy t·∫Øc ƒë·∫∑t t√™n config.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkfOq_Iy8doi","outputId":"ef851c27-82ff-4f9d-9f3d-9b9543180d54","executionInfo":{"status":"ok","timestamp":1766432100374,"user_tz":-420,"elapsed":540,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\n","‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\n","‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong configs/nerf-gan-carla.yaml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 8:** Ch·∫°y training"],"metadata":{"id":"zDfpdi4hJoUR"}},{"cell_type":"code","source":["print(\"üöÄ B·∫Øt ƒë·∫ßu Training...\")\n","\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  python src/infra/launch_local.py hydra.run.dir=. \\\n","  +experiment_name=carla_128_t4_run1 \\\n","  +dataset.name=carla_128 \\\n","  +dataset.root_path={LOCAL_PATH} \\\n","  num_gpus=1 \\\n","  +D_kwargs.patch_size=32 \\\n","  +G_kwargs.synthesis_kwargs.patch_size=32 \\\n","  +G_kwargs.cfg.patch_size=32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW-LiDXf542l","outputId":"13a4aefc-c379-42ff-846c-da1fd8395532"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ B·∫Øt ƒë·∫ßu Training...\n","<=== CONFIG ===>\n","env:\n","  python_bin: python\n","  base_project_dir: ${hydra:runtime.cwd}\n","  before_train_commands: []\n","  torch_extensions_dir: /tmp/torch_extensions\n","  datasets_dir: data\n","  objects_to_copy:\n","  - ${env.base_project_dir}/src\n","  - ${env.base_project_dir}/configs\n","  symlinks_to_create:\n","  - ${env.base_project_dir}/data\n","num_gpus: 1\n","dataset:\n","  source_path: ${env.datasets_dir}/${dataset.name}.zip\n","  target_path: data/${dataset.name}.zip\n","  name: carla_128\n","  root_path: /content/carla_128.zip\n","print_only: false\n","project_release_dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None\n","train_args:\n","  outdir: ${project_release_dir}\n","  data: ${dataset.target_path}\n","  gpus: ${num_gpus}\n","  metrics: fid1k_full\n","  cfg: nerf\n","  generate_video: true\n","  video_front_view: true\n","  snap: 50\n","  aug: fixed\n","  augpipe: crop\n","  p: 0.5\n","  mirror: 1\n","  hydra_cfg_name: nerf-gan-carla.yml\n","train_args_str: --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None\n","  --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True\n","  --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.5 --mirror=1\n","  --hydra_cfg_name=nerf-gan-carla.yml\n","experiment_name: carla_128_t4_run1\n","D_kwargs:\n","  patch_size: 32\n","G_kwargs:\n","  synthesis_kwargs:\n","    patch_size: 32\n","  cfg:\n","    patch_size: 32\n","\n","<=== TRAINING COMMAND ===>\n","\n"," TORCH_EXTENSIONS_DIR=/tmp/torch_extensions python src/train.py --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.5 --mirror=1 --hydra_cfg_name=nerf-gan-carla.yml\n","Creating a symlink to /content/drive/MyDrive/HyperNeRFGAN/data, so try not to delete it occasionally!\n","Created a project dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None\n","src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 50,\n","  \"network_snapshot_ticks\": 50,\n","  \"generate_video\": true,\n","  \"video_front_view\": true,\n","  \"metrics\": [\n","    \"fid1k_full\"\n","  ],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"data/carla_128.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 10000,\n","    \"xflip\": true,\n","    \"resolution\": 128\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"patch_size\": 32,\n","    \"channel_max\": 512,\n","    \"channel_base\": 32768,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.NeRFGenerator\",\n","    \"z_dim\": 128,\n","    \"w_dim\": 128,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"synthesis_kwargs\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 32,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"use_normal\": false,\n","      \"theta_std\": 1.0\n","    },\n","    \"cfg\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 32,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"fmm\": {\n","        \"enabled\": true,\n","        \"rank\": 10,\n","        \"activation\": \"demod\"\n","      }\n","    }\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 1.0,\n","    \"style_mixing_prob\": 0.0,\n","    \"pl_weight\": 0\n","  },\n","  \"total_kimg\": 25000,\n","  \"batch_size\": 4,\n","  \"batch_gpu\": 4,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": 0.05,\n","  \"augment_p\": 0.5,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"crop\": true,\n","    \"xflip\": 1\n","  },\n","  \"run_dir\": \"/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0.5-crop\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0.5-crop\n","Training data:      data/carla_128.zip\n","Training duration:  25000 kimg\n","Number of GPUs:     1\n","Number of images:   10000\n","Image resolution:   128\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Num images:  20000\n","Image shape: [3, 128, 128]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\n","NeRFGenerator                   Parameters  Buffers  Input Shape              Output shape      Datatype\n","---                             ---         ---      ---                      ---               ---     \n","mapping.fc0                     16512       -        [4, 128]                 [4, 128]          float32 \n","mapping.fc1                     16512       -        [4, 128]                 [4, 128]          float32 \n","synthesis.pts_linears.0.affine  246390      -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         8192        -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  170280      -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         516         -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis                       -           -        [4, 128]                 [4, 3, 128, 128]  float32 \n","---                             ---         ---      ---                      ---               ---     \n","Total                           1498658     0        -                        -                 -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Input Shape       Output shape      Datatype\n","---            ---         ---      ---               ---               ---     \n","b32.fromrgb    2048        16       [4, 3, 32, 32]    [4, 512, 32, 32]  float16 \n","b32.skip       262144      16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32.conv0      2359808     16       [4, 512, 32, 32]  [4, 512, 32, 32]  float16 \n","b32.conv1      2359808     16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32            -           16       [4, 3, 32, 32]    [4, 512, 16, 16]  float16 \n","b16.skip       262144      16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16.conv0      2359808     16       [4, 512, 16, 16]  [4, 512, 16, 16]  float16 \n","b16.conv1      2359808     16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16            -           16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b8.skip        262144      16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8.conv0       2359808     16       [4, 512, 8, 8]    [4, 512, 8, 8]    float16 \n","b8.conv1       2359808     16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8             -           16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b4.mbstd       -           -        [4, 512, 4, 4]    [4, 513, 4, 4]    float32 \n","b4.conv        2364416     16       [4, 513, 4, 4]    [4, 512, 4, 4]    float32 \n","b4.fc          4194816     -        [4, 8192]         [4, 512]          float32 \n","b4.out         513         -        [4, 512]          [4, 1]            float32 \n","---            ---         ---      ---               ---               ---     \n","Total          21507073    224      -                 -                 -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 7m 22s       sec/tick 1.2     sec/kimg 300.99  maintenance 440.5  cpumem 4.57   gpumem 8.44   augment 0.500\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_t4_run1-None ...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_t4_run1-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","{\"results\": {\"fid1k_full\": 339.94084375502814}, \"metric\": \"fid1k_full\", \"total_time\": 412.8391923904419, \"total_time_str\": \"6m 53s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1766433895.0101984}\n","tick 1     kimg 4.0      time 33m 53s      sec/tick 277.9   sec/kimg 69.48   maintenance 1313.6 cpumem 4.94   gpumem 3.31   augment 0.500\n","tick 2     kimg 8.0      time 38m 30s      sec/tick 276.6   sec/kimg 69.15   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 3     kimg 12.0     time 43m 07s      sec/tick 277.1   sec/kimg 69.27   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 4     kimg 16.0     time 47m 43s      sec/tick 275.7   sec/kimg 68.93   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 5     kimg 20.0     time 52m 18s      sec/tick 275.1   sec/kimg 68.76   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 6     kimg 24.0     time 56m 56s      sec/tick 278.0   sec/kimg 69.50   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 7     kimg 28.0     time 1h 01m 30s   sec/tick 273.4   sec/kimg 68.36   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 8     kimg 32.0     time 1h 06m 00s   sec/tick 269.8   sec/kimg 67.45   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 9     kimg 36.0     time 1h 10m 35s   sec/tick 275.0   sec/kimg 68.75   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 10    kimg 40.0     time 1h 15m 15s   sec/tick 280.0   sec/kimg 70.00   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 11    kimg 44.0     time 1h 19m 51s   sec/tick 275.7   sec/kimg 68.93   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 12    kimg 48.0     time 1h 24m 28s   sec/tick 276.8   sec/kimg 69.19   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 13    kimg 52.0     time 1h 29m 07s   sec/tick 278.9   sec/kimg 69.73   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 14    kimg 56.0     time 1h 33m 42s   sec/tick 274.9   sec/kimg 68.72   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 15    kimg 60.0     time 1h 38m 15s   sec/tick 273.5   sec/kimg 68.37   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 16    kimg 64.0     time 1h 42m 47s   sec/tick 271.6   sec/kimg 67.90   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 17    kimg 68.0     time 1h 47m 24s   sec/tick 276.8   sec/kimg 69.21   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 18    kimg 72.0     time 1h 51m 53s   sec/tick 268.9   sec/kimg 67.22   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 19    kimg 76.0     time 1h 56m 22s   sec/tick 269.0   sec/kimg 67.26   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 20    kimg 80.0     time 2h 00m 48s   sec/tick 265.7   sec/kimg 66.42   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 21    kimg 84.0     time 2h 05m 16s   sec/tick 267.8   sec/kimg 66.95   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 22    kimg 88.0     time 2h 09m 44s   sec/tick 267.9   sec/kimg 66.97   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 23    kimg 92.0     time 2h 14m 13s   sec/tick 269.7   sec/kimg 67.42   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 24    kimg 96.0     time 2h 18m 40s   sec/tick 267.0   sec/kimg 66.74   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 25    kimg 100.0    time 2h 23m 07s   sec/tick 266.3   sec/kimg 66.59   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 26    kimg 104.0    time 2h 27m 30s   sec/tick 263.4   sec/kimg 65.86   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 27    kimg 108.0    time 2h 32m 05s   sec/tick 274.9   sec/kimg 68.72   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 28    kimg 112.0    time 2h 36m 44s   sec/tick 278.4   sec/kimg 69.59   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 29    kimg 116.0    time 2h 41m 25s   sec/tick 281.5   sec/kimg 70.38   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 30    kimg 120.0    time 2h 46m 00s   sec/tick 274.3   sec/kimg 68.57   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 31    kimg 124.0    time 2h 50m 34s   sec/tick 273.9   sec/kimg 68.47   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 32    kimg 128.0    time 2h 55m 18s   sec/tick 284.1   sec/kimg 71.02   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 33    kimg 132.0    time 2h 59m 56s   sec/tick 278.0   sec/kimg 69.50   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 34    kimg 136.0    time 3h 04m 35s   sec/tick 278.7   sec/kimg 69.67   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 35    kimg 140.0    time 3h 09m 14s   sec/tick 279.2   sec/kimg 69.80   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 36    kimg 144.0    time 3h 13m 53s   sec/tick 278.9   sec/kimg 69.72   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 37    kimg 148.0    time 3h 18m 30s   sec/tick 276.7   sec/kimg 69.16   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 38    kimg 152.0    time 3h 23m 08s   sec/tick 277.9   sec/kimg 69.46   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 39    kimg 156.0    time 3h 27m 44s   sec/tick 275.9   sec/kimg 68.96   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 40    kimg 160.0    time 3h 32m 19s   sec/tick 275.1   sec/kimg 68.77   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 41    kimg 164.0    time 3h 36m 53s   sec/tick 274.1   sec/kimg 68.54   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 42    kimg 168.0    time 3h 41m 34s   sec/tick 281.0   sec/kimg 70.25   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 43    kimg 172.0    time 3h 46m 14s   sec/tick 279.8   sec/kimg 69.96   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 44    kimg 176.0    time 3h 50m 53s   sec/tick 278.9   sec/kimg 69.71   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 45    kimg 180.0    time 3h 55m 31s   sec/tick 277.9   sec/kimg 69.47   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 46    kimg 184.0    time 4h 00m 07s   sec/tick 275.4   sec/kimg 68.84   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 47    kimg 188.0    time 4h 04m 42s   sec/tick 275.0   sec/kimg 68.76   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 48    kimg 192.0    time 4h 09m 18s   sec/tick 276.0   sec/kimg 69.00   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 49    kimg 196.0    time 4h 13m 53s   sec/tick 274.9   sec/kimg 68.71   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","tick 50    kimg 200.0    time 4h 18m 29s   sec/tick 275.5   sec/kimg 68.87   maintenance 0.1    cpumem 4.94   gpumem 0.82   augment 0.500\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_t4_run1-None ...\n","{\"results\": {\"fid1k_full\": 155.4421388406944}, \"metric\": \"fid1k_full\", \"total_time\": 260.9888381958008, \"total_time_str\": \"4m 21s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1766448750.4626083}\n","tick 51    kimg 204.0    time 4h 41m 37s   sec/tick 286.1   sec/kimg 71.53   maintenance 1102.3 cpumem 5.39   gpumem 1.54   augment 0.500\n","tick 52    kimg 208.0    time 4h 46m 19s   sec/tick 282.0   sec/kimg 70.50   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 53    kimg 212.0    time 4h 50m 57s   sec/tick 278.0   sec/kimg 69.51   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 54    kimg 216.0    time 4h 55m 32s   sec/tick 274.4   sec/kimg 68.60   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 55    kimg 220.0    time 5h 00m 11s   sec/tick 279.5   sec/kimg 69.88   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 56    kimg 224.0    time 5h 04m 51s   sec/tick 280.0   sec/kimg 69.99   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 57    kimg 228.0    time 5h 09m 30s   sec/tick 278.8   sec/kimg 69.69   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 58    kimg 232.0    time 5h 14m 10s   sec/tick 279.2   sec/kimg 69.81   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 59    kimg 236.0    time 5h 18m 47s   sec/tick 277.3   sec/kimg 69.32   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 60    kimg 240.0    time 5h 23m 23s   sec/tick 276.0   sec/kimg 69.00   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 61    kimg 244.0    time 5h 28m 00s   sec/tick 277.3   sec/kimg 69.31   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 62    kimg 248.0    time 5h 32m 36s   sec/tick 275.6   sec/kimg 68.91   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 63    kimg 252.0    time 5h 37m 12s   sec/tick 275.9   sec/kimg 68.97   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 64    kimg 256.0    time 5h 41m 47s   sec/tick 275.0   sec/kimg 68.74   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 65    kimg 260.0    time 5h 46m 18s   sec/tick 270.3   sec/kimg 67.58   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 66    kimg 264.0    time 5h 50m 49s   sec/tick 271.1   sec/kimg 67.78   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 67    kimg 268.0    time 5h 55m 15s   sec/tick 266.2   sec/kimg 66.56   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 68    kimg 272.0    time 5h 59m 47s   sec/tick 271.5   sec/kimg 67.88   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 69    kimg 276.0    time 6h 04m 19s   sec/tick 271.7   sec/kimg 67.93   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 70    kimg 280.0    time 6h 08m 52s   sec/tick 273.4   sec/kimg 68.35   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 71    kimg 284.0    time 6h 13m 25s   sec/tick 272.5   sec/kimg 68.12   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 72    kimg 288.0    time 6h 18m 03s   sec/tick 278.6   sec/kimg 69.64   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 73    kimg 292.0    time 6h 22m 42s   sec/tick 279.0   sec/kimg 69.75   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 74    kimg 296.0    time 6h 27m 16s   sec/tick 273.4   sec/kimg 68.34   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 75    kimg 300.0    time 6h 31m 51s   sec/tick 274.7   sec/kimg 68.68   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 76    kimg 304.0    time 6h 36m 25s   sec/tick 273.7   sec/kimg 68.44   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 77    kimg 308.0    time 6h 41m 01s   sec/tick 276.0   sec/kimg 68.99   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 78    kimg 312.0    time 6h 45m 41s   sec/tick 279.9   sec/kimg 69.99   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 79    kimg 316.0    time 6h 50m 24s   sec/tick 283.5   sec/kimg 70.88   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 80    kimg 320.0    time 6h 55m 00s   sec/tick 275.1   sec/kimg 68.79   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 81    kimg 324.0    time 6h 59m 34s   sec/tick 274.3   sec/kimg 68.59   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 82    kimg 328.0    time 7h 04m 09s   sec/tick 275.1   sec/kimg 68.78   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 83    kimg 332.0    time 7h 08m 47s   sec/tick 278.0   sec/kimg 69.50   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 84    kimg 336.0    time 7h 13m 31s   sec/tick 283.3   sec/kimg 70.82   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 85    kimg 340.0    time 7h 18m 19s   sec/tick 287.7   sec/kimg 71.94   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 86    kimg 344.0    time 7h 23m 11s   sec/tick 292.5   sec/kimg 73.13   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 87    kimg 348.0    time 7h 27m 56s   sec/tick 285.3   sec/kimg 71.32   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n","tick 88    kimg 352.0    time 7h 32m 43s   sec/tick 286.8   sec/kimg 71.69   maintenance 0.1    cpumem 5.39   gpumem 0.82   augment 0.500\n"]}]}]}