{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaeJec9JTxKQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Z52bbRT37I"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pathlib\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/HyperNeRFGan/src\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from nerf.load_blender import pose_spherical\n",
        "import torch\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAbENWgjA-J4"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiDL9JeLT582"
      },
      "outputs": [],
      "source": [
        "batch_size = 1\n",
        "num_images = 20\n",
        "interp_examples = 5\n",
        "interp_steps = 10\n",
        "\n",
        "pickle_name = \"carla_improved_1600\"\n",
        "pickle_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGan/data/pickles/{pickle_name}.pkl\")\n",
        "img_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGan/pretrained_running/samples/images/{pickle_name}\")\n",
        "interpolation_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGan/pretrained_running/samples/interpolation/{pickle_name}\")\n",
        "\n",
        "img_path.mkdir(parents=True, exist_ok=True)\n",
        "interpolation_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiu8GADJURxF"
      },
      "outputs": [],
      "source": [
        "def get_interpolated_images(G, num_steps=8):\n",
        "    z1 = torch.randn(1, 128, device=device)\n",
        "    z2 = torch.randn(1, 128, device=device)\n",
        "\n",
        "    alphas = torch.linspace(0, 1, steps=num_steps, device=device).unsqueeze(1)\n",
        "    interpolated_vectors = (1 - alphas) * z1 + alphas * z2  # (S,128)\n",
        "\n",
        "    poses = [pose_spherical(theta=30, phi=-30, radius=4.0)] * num_steps\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
        "            images = G(\n",
        "                z=interpolated_vectors,\n",
        "                c=None,\n",
        "                poses=poses,\n",
        "                scale=False,\n",
        "                crop=False,\n",
        "                perturb=False,\n",
        "            )\n",
        "\n",
        "    images = images.float().permute((0, 2, 3, 1)).cpu()\n",
        "    return images\n",
        "\n",
        "\n",
        "def make_interpolation_examples(G, interpolation_path, interpolation_examples=4, num_steps=8):\n",
        "    for i in range(interpolation_examples):\n",
        "        images = get_interpolated_images(G, num_steps=num_steps)\n",
        "\n",
        "        plt.clf()\n",
        "        fig, axs = plt.subplots(1, num_steps, figsize=(2.5 * num_steps, 3), tight_layout=True)\n",
        "\n",
        "        for j, ax in enumerate(axs):\n",
        "            ax.imshow(images[j])\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        fig.savefig(interpolation_path.joinpath(f\"{i}.png\"), dpi=120)\n",
        "        plt.close(fig)\n",
        "\n",
        "        del images\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "def make_image_examples(G, num_images, batch_size, result_path):\n",
        "    to_pil = transforms.ToPILImage()\n",
        "\n",
        "    epochs = (num_images + batch_size - 1) // batch_size\n",
        "    counter = 0\n",
        "\n",
        "    for i in tqdm(range(epochs)):\n",
        "        cur_bs = min(batch_size, num_images - counter)\n",
        "        z = torch.randn(cur_bs, 128, device=device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\"), dtype=torch.float16):\n",
        "                imgs = G(z=z, c=None, scale=False, crop=False, perturb=False)\n",
        "\n",
        "        imgs = imgs.float().cpu()\n",
        "\n",
        "        for j, img in enumerate(imgs):\n",
        "            counter += 1\n",
        "            image_name = result_path / f\"{counter}.png\"\n",
        "            to_pil(img).save(image_name)\n",
        "\n",
        "        del imgs, z\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcjnFBx0UVxF"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    with pickle_path.open(\"rb\") as f:\n",
        "        content = pickle.load(f)\n",
        "\n",
        "    G = content[\"G_ema\"].eval().to(device)\n",
        "\n",
        "    print(\"Generating interpolation examples...\")\n",
        "    torch.manual_seed(0)\n",
        "    make_interpolation_examples(G, interpolation_path, interpolation_examples=interp_examples, num_steps=interp_steps)\n",
        "\n",
        "    print(\"Generating images...\")\n",
        "    torch.manual_seed(0)\n",
        "    make_image_examples(G, num_images, batch_size, img_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
