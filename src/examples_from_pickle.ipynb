{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KaeJec9JTxKQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f3495f65-2e8a-4d1d-e7ba-482d38878989"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3Z52bbRT37I"},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/HyperNeRFGAN/src\")\n","\n","import pickle\n","import pathlib\n","\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from nerf.load_blender import pose_spherical\n","import torch\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiDL9JeLT582"},"outputs":[],"source":["batch_size = 1\n","num_images = 10\n","interp_examples = 5\n","interp_steps = 10\n","\n","pickle_name = \"carla_improved_1600\"\n","pickle_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGAN/data/pickles/{pickle_name}.pkl\")\n","img_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGAN/pretrained_running/images/{pickle_name}\")\n","interpolation_path = pathlib.Path(f\"/content/drive/MyDrive/HyperNeRFGAN/pretrained_running/interpolation/{pickle_name}\")\n","\n","img_path.mkdir(parents=True, exist_ok=True)\n","interpolation_path.mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qiu8GADJURxF"},"outputs":[],"source":["def get_interpolated_images(G, num_steps=10):\n","    z1 = torch.randn(1, 128)\n","    z2 = torch.randn(1, 128)\n","\n","    interpolated_vectors = torch.zeros(num_steps, 128)\n","\n","    for i in tqdm(range(num_steps)):\n","        alpha = i / (num_steps - 1)\n","        interpolated_vectors[i] = (1 - alpha) * z1 + alpha * z2\n","\n","    images = G(\n","        z=interpolated_vectors,\n","        c=None,\n","        poses=[pose_spherical(theta=30, phi=-30, radius=4.0)] * num_steps,\n","        scale=False,\n","        crop=False,\n","        perturb=False,\n","    )\n","    images = images.permute((0, 2, 3, 1))\n","\n","    return images\n","\n","\n","def make_interpolation_examples(\n","    G, interpolation_path, interpolation_examples=interp_examples, num_steps=interp_steps\n","):\n","    for i in range(interpolation_examples):\n","        images = get_interpolated_images(G, num_steps=num_steps)\n","        plt.clf()\n","        fig, axs = plt.subplots(1, num_steps, figsize=(50, 5), tight_layout=True)\n","\n","        for j, ax in enumerate(axs):\n","            ax.imshow(images[j])\n","            ax.axis(\"off\")\n","\n","        fig.savefig(interpolation_path.joinpath(f\"{i}.png\"))\n","\n","\n","def make_image_examples(G, num_images, batch_size, result_path):\n","    epochs = int(num_images / batch_size + 1)\n","    for i in tqdm(range(epochs)):\n","        z = torch.randn(batch_size, 128)\n","        imgs = G(z=z, c=None, scale=False, crop=False, perturb=False)\n","\n","        for j, img in enumerate(imgs):\n","            image_name = result_path / f\"{i * batch_size + j + 1}.png\"\n","            transforms.ToPILImage()(img).save(image_name)"]},{"cell_type":"code","source":["import numpy as np\n","\n","if not hasattr(np, \"float\"):\n","    np.float = float\n","\n","if not hasattr(np, \"int\"):\n","    np.int = int\n","\n","if not hasattr(np, \"bool\"):\n","    np.bool = bool"],"metadata":{"id":"wv64CpPQNaR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RcjnFBx0UVxF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b13437b8-fc6b-4a52-b9c6-2046170991c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating interpolation examples...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 6535.22it/s]\n","/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]}],"source":["if __name__ == \"__main__\":\n","    with pickle_path.open(\"rb\") as f:\n","        content = pickle.load(f)\n","\n","    G = content[\"G_ema\"].eval()\n","\n","    print(\"Generating interpolation examples...\")\n","    torch.manual_seed(0)\n","    make_interpolation_examples(G, interpolation_path)\n","\n","    print(\"Generating images...\")\n","    torch.manual_seed(0)\n","    make_image_examples(G, num_images, batch_size, img_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}