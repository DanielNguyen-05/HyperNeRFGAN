{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **B∆∞·ªõc 1:** Mount Drive v√† Khai b√°o c√°c ƒë∆∞·ªùng d·∫´n"],"metadata":{"id":"dmIxkfqTG5_w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODg49OX-tRMK","collapsed":true},"outputs":[],"source":["from google.colab import drive\n","import os, shutil\n","\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')"]},{"cell_type":"code","source":["DATASET_NAME = \"carla_128\"\n","ZIP_FILE = f\"{DATASET_NAME}.zip\"\n","DRIVE_PATH = f\"/content/drive/MyDrive/HyperNeRFGAN/data/{ZIP_FILE}\"\n","LOCAL_PATH = f\"/content/{ZIP_FILE}\""],"metadata":{"id":"hVjQhNEDKk0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 2:** Copy dataset xu·ªëng Local (ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω)\n"],"metadata":{"id":"vEhfn8UDHErI"}},{"cell_type":"code","source":["if os.path.exists(DRIVE_PATH):\n","    print(f\"üîÑ ƒêang copy {ZIP_FILE} t·ª´ Drive xu·ªëng Local...\")\n","    shutil.copy(DRIVE_PATH, LOCAL_PATH)\n","    print(f\"‚úÖ ƒê√£ copy xong: {LOCAL_PATH}\")\n","else:\n","    raise FileNotFoundError(f\"‚ùå Kh√¥ng t√¨m th·∫•y file: {DRIVE_PATH}. H√£y ki·ªÉm tra l·∫°i folder data tr√™n Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3yWDXnt5s8V","outputId":"0fda4e87-ab00-416a-ca22-47d92f534cdd","executionInfo":{"status":"ok","timestamp":1766573154999,"user_tz":-420,"elapsed":821,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ ƒêang copy carla_128.zip t·ª´ Drive xu·ªëng Local...\n","‚úÖ ƒê√£ copy xong: /content/carla_128.zip\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 3:** C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Micromamba"],"metadata":{"id":"ep5UCTRXHxD5"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/HyperNeRFGAN\n","\n","# C√†i Micromamba\n","!mkdir -p bin\n","!curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n","!chmod +x bin/micromamba\n","\n","# T·∫°o file environment t·ªëi ∆∞u cho Colab\n","import yaml\n","env_in = \"environment.yaml\"\n","env_out = \"environment_colab.yaml\"\n","\n","# Load environment g·ªëc v√† l·ªçc b·ªè imageio-ffmpeg (c√†i pip sau)\n","if os.path.exists(env_in):\n","    y = yaml.safe_load(open(env_in, \"r\"))\n","    y[\"channels\"] = [\"conda-forge\", \"defaults\"] # B·ªè pytorch channel ƒë·ªÉ c√†i th·ªß c√¥ng\n","    deps = []\n","    for d in y.get(\"dependencies\", []):\n","        if isinstance(d, str) and (d.startswith(\"imageio-ffmpeg\") or d.startswith(\"pytorch\") or d.startswith(\"torchvision\")):\n","            continue\n","        deps.append(d)\n","    y[\"dependencies\"] = deps\n","    with open(env_out, \"w\") as f:\n","        yaml.safe_dump(y, f, sort_keys=False)\n","else:\n","    with open(env_out, \"w\") as f:\n","        f.write(\"channels:\\n  - conda-forge\\ndependencies:\\n  - python=3.8\\n  - pip\\n\")\n","\n","print(\"‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng:\", env_out)\n","\n","# T·∫°o m√¥i tr∆∞·ªùng\n","ENV_PREFIX = \"/content/hypernerfgan_env\"\n","!rm -rf {ENV_PREFIX}\n","!./bin/micromamba create -y -p {ENV_PREFIX} -f environment_colab.yaml\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H0_0P8E15xzF","outputId":"edb65917-8264-4c4f-9f47-9dab29fadff6","executionInfo":{"status":"ok","timestamp":1766573198409,"user_tz":-420,"elapsed":43407,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HyperNeRFGAN\n","bin/micromamba\n","‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng: environment_colab.yaml\n","conda-forge/linux-64                                        Using cache\n","conda-forge/noarch                                          Using cache\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m Please make sure you understand Anaconda Terms of Services.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m See: https://legal.anaconda.com/policies/en/\n","\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n","\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n","pkgs/main/noarch  ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25h\n","\n","Transaction\n","\n","  Prefix: /content/hypernerfgan_env\n","\n","  Updating specs:\n","\n","   - python=3.8.5\n","   - pip=20.3\n","   - cudatoolkit=10.2\n","   - imageio\n","   - protobuf=3.20.1\n","   - pip\n","\n","\n","  Package                Version  Build                 Channel           Size\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","  Install:\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu                 conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ca-certificates \u001b[0m  2025.11.12  hbd8a1cb_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ cudatoolkit     \u001b[0m     10.2.89  hdec6ad0_13           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ freetype        \u001b[0m      2.12.1  h267a509_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ imageio         \u001b[0m      2.36.0  pyh12aca89_1          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lcms2           \u001b[0m        2.16  hb7c19ff_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.45  bootstrap_ha15bf96_5  conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lerc            \u001b[0m       4.0.0  h0aef613_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libblas         \u001b[0m      3.11.0  5_h4a7cf45_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libcblas        \u001b[0m      3.11.0  5_h0358290_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libdeflate      \u001b[0m        1.20  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libffi          \u001b[0m       3.2.1  he1b5a44_1007         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc          \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc-ng       \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran     \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran5    \u001b[0m      15.2.0  h68bc16d_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgomp         \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libjpeg-turbo   \u001b[0m       3.1.2  hb03c661_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblapack       \u001b[0m      3.11.0  5_h47877c9_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma         \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma-devel   \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libopenblas     \u001b[0m      0.3.30  pthreads_h94d23a6_4   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libpng          \u001b[0m      1.6.43  h2797004_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libprotobuf     \u001b[0m      3.20.1  h6239696_4            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libsqlite       \u001b[0m      3.46.0  hde9e2c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx       \u001b[0m      15.2.0  h934c35e_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx-ng    \u001b[0m      15.2.0  hdf11a46_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libtiff         \u001b[0m       4.6.0  h1dd3fc0_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libwebp-base    \u001b[0m       1.6.0  hd42ef1d_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libxcb          \u001b[0m        1.15  h0b41bf4_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libzlib         \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ncurses         \u001b[0m         6.5  h2d0b736_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ numpy           \u001b[0m      1.24.4  py38h59b608b_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openjpeg        \u001b[0m       2.5.2  h488ebb8_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openssl         \u001b[0m      1.1.1w  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pillow          \u001b[0m      10.3.0  py38h9e66945_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pip             \u001b[0m      20.3.4  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ protobuf        \u001b[0m      3.20.1  py38hfa26641_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pthread-stubs   \u001b[0m         0.4  hb9d3cd8_1002         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python          \u001b[0m       3.8.5  h1103e12_9_cpython    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python_abi      \u001b[0m         3.8  8_cp38                conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ readline        \u001b[0m         8.3  h853b02a_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ setuptools      \u001b[0m      75.3.0  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ six             \u001b[0m      1.16.0  pyh6c4a22f_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ sqlite          \u001b[0m      3.46.0  h6d4b2fc_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_h4845f30_101    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxau     \u001b[0m      1.0.12  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxdmcp   \u001b[0m       1.1.5  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz              \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-gpl-tools    \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-tools        \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zlib            \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zstd            \u001b[0m       1.5.6  ha6fb4c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","\n","  Summary:\n","\n","  Install: 55 packages\n","\n","  Total download: 0 B\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","\n","Transaction starting\n","\u001b[?25l\u001b[2K\u001b[0G\u001b[?25hLinking python_abi-3.8-8_cp38\n","Linking ca-certificates-2025.11.12-hbd8a1cb_0\n","Linking libgomp-15.2.0-he0feb66_16\n","Linking _libgcc_mutex-0.1-conda_forge\n","Linking ld_impl_linux-64-2.45-bootstrap_ha15bf96_5\n","Linking _openmp_mutex-4.5-2_gnu\n","Linking libgcc-15.2.0-he0feb66_16\n","Linking libgfortran5-15.2.0-h68bc16d_16\n","Linking ncurses-6.5-h2d0b736_3\n","Linking libjpeg-turbo-3.1.2-hb03c661_0\n","Linking xorg-libxdmcp-1.1.5-hb03c661_1\n","Linking xorg-libxau-1.0.12-hb03c661_1\n","Linking pthread-stubs-0.4-hb9d3cd8_1002\n","Linking libwebp-base-1.6.0-hd42ef1d_0\n","Linking libstdcxx-15.2.0-h934c35e_16\n","Linking libgcc-ng-15.2.0-h69a702a_16\n","Linking liblzma-5.8.1-hb9d3cd8_2\n","Linking libgfortran-15.2.0-h69a702a_16\n","Linking readline-8.3-h853b02a_0\n","Linking lerc-4.0.0-h0aef613_1\n","Linking libstdcxx-ng-15.2.0-hdf11a46_16\n","Linking openssl-1.1.1w-hd590300_0\n","Linking libxcb-1.15-h0b41bf4_0\n","Linking libdeflate-1.20-hd590300_0\n","Linking libzlib-1.2.13-h4ab18f5_6\n","Linking xz-tools-5.8.1-hb9d3cd8_2\n","Linking xz-gpl-tools-5.8.1-hbcc6ac9_2\n","Linking liblzma-devel-5.8.1-hb9d3cd8_2\n","Linking libopenblas-0.3.30-pthreads_h94d23a6_4\n","Linking libffi-3.2.1-he1b5a44_1007\n","Linking cudatoolkit-10.2.89-hdec6ad0_13\n","By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n","\n","Linking libsqlite-3.46.0-hde9e2c9_0\n","Linking zstd-1.5.6-ha6fb4c9_0\n","Linking libpng-1.6.43-h2797004_0\n","Linking tk-8.6.13-noxft_h4845f30_101\n","Linking libprotobuf-3.20.1-h6239696_4\n","Linking zlib-1.2.13-h4ab18f5_6\n","Linking xz-5.8.1-hbcc6ac9_2\n","Linking libblas-3.11.0-5_h4a7cf45_openblas\n","Linking sqlite-3.46.0-h6d4b2fc_0\n","Linking freetype-2.12.1-h267a509_2\n","Linking libtiff-4.6.0-h1dd3fc0_3\n","Linking libcblas-3.11.0-5_h0358290_openblas\n","Linking liblapack-3.11.0-5_h47877c9_openblas\n","Linking python-3.8.5-h1103e12_9_cpython\n","Linking lcms2-2.16-hb7c19ff_0\n","Linking openjpeg-2.5.2-h488ebb8_0\n","Linking wheel-0.45.1-pyhd8ed1ab_0\n","Linking setuptools-75.3.0-pyhd8ed1ab_0\n","Linking pip-20.3.4-pyhd8ed1ab_0\n","Linking six-1.16.0-pyh6c4a22f_0\n","Linking pillow-10.3.0-py38h9e66945_0\n","Linking numpy-1.24.4-py38h59b608b_0\n","Linking protobuf-3.20.1-py38hfa26641_0\n","Linking imageio-2.36.0-pyh12aca89_1\n","\n","Transaction finished\n","\n","\n","To activate this environment, use:\n","\n","    micromamba activate /content/hypernerfgan_env\n","\n","Or to execute a single command in this environment, use:\n","\n","    micromamba run -p /content/hypernerfgan_env mycommand\n","\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m You are using 'pip' as an additional package manager.\n","    Be aware that packages installed with 'pip' are managed independently from 'conda-forge' channel.\n","\u001b[36m\n","Installing pip packages: hydra-core==1.0.6, click==7.1.2, scipy==1.6.1, ninja==1.10.0, tensorboard==2.4.1, tqdm==4.59.0, gitpython, gpustat, opencv-python, -e .\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 4:** C√†i ƒë·∫∑t Pytorch v√† Dependencies"],"metadata":{"id":"ADOxSyjKIQC9"}},{"cell_type":"code","source":["print(\"‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\")\n","\n","# 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","  --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# 2. C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈© (Quan tr·ªçng)\n","# (Pip 23.3.1 ƒë·ªÉ fix l·ªói omegaconf, Setuptools<59.6 ƒë·ªÉ fix l·ªói distutils)\n","!./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","!./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# 4. C√†i Hydra & Dependencies\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# 5. C√†i c√°c util kh√°c\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja\n","\n","print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n","\n","\n","# # 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","#   --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# # 2. QUAN TR·ªåNG: C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈©\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# # 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# # 4. C√†i Hydra & Dependencies\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# # 5. C√†i c√°c util kh√°c V√Ä CH·ªêT NUMPY 1.23.5\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja \"numpy==1.23.5\"\n","\n","# print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXOuH6435y1i","outputId":"56045591-9767-4576-da7c-19aeccb7ad6d","collapsed":true,"executionInfo":{"status":"ok","timestamp":1766573382320,"user_tz":-420,"elapsed":183916,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\n","Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.10.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1821.4 MB 2.2 kB/s \n","\u001b[?25hCollecting torchvision==0.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (21.8 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.8 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from torch==1.10.0+cu113) (4.13.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (10.3.0)\n","Requirement already satisfied: numpy in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (1.24.4)\n","Installing collected packages: torch, torchvision\n","Successfully installed torch-1.10.0+cu113 torchvision-0.11.0+cu113\n","Collecting pip==23.3.1\n","  Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n","Collecting setuptools<59.6.0\n","  Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n","Requirement already satisfied: wheel in /content/hypernerfgan_env/lib/python3.8/site-packages (0.45.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.3.0\n","    Uninstalling setuptools-75.3.0:\n","      Successfully uninstalled setuptools-75.3.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.3.4\n","    Uninstalling pip-20.3.4:\n","      Successfully uninstalled pip-20.3.4\n","Successfully installed pip-23.3.1 setuptools-59.5.0\n","Obtaining file:///content/drive/MyDrive/HyperNeRFGAN\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: inr-gan\n","  Attempting uninstall: inr-gan\n","    Found existing installation: inr_gan 0.0.1\n","    Uninstalling inr_gan-0.0.1:\n","      Successfully uninstalled inr_gan-0.0.1\n","  Running setup.py develop for inr-gan\n","Successfully installed inr-gan-0.0.1\n","Requirement already satisfied: hydra-core==1.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (1.0.6)\n","Requirement already satisfied: omegaconf==2.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (2.0.6)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (4.8)\n","Requirement already satisfied: importlib-resources in /content/hypernerfgan_env/lib/python3.8/site-packages (from hydra-core==1.0.6) (6.4.5)\n","Requirement already satisfied: PyYAML>=5.1.* in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (6.0.3)\n","Requirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (4.13.2)\n","Requirement already satisfied: zipp>=3.1.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-resources->hydra-core==1.0.6) (3.20.2)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mCollecting imageio-ffmpeg\n","  Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: opencv-python in /content/hypernerfgan_env/lib/python3.8/site-packages (4.12.0.88)\n","Requirement already satisfied: tensorboard in /content/hypernerfgan_env/lib/python3.8/site-packages (2.4.1)\n","Requirement already satisfied: tqdm in /content/hypernerfgan_env/lib/python3.8/site-packages (4.59.0)\n","Requirement already satisfied: gpustat in /content/hypernerfgan_env/lib/python3.8/site-packages (1.1.1)\n","Requirement already satisfied: gitpython in /content/hypernerfgan_env/lib/python3.8/site-packages (3.1.45)\n","Requirement already satisfied: ninja in /content/hypernerfgan_env/lib/python3.8/site-packages (1.10.0)\n","Requirement already satisfied: setuptools in /content/hypernerfgan_env/lib/python3.8/site-packages (from imageio-ffmpeg) (59.5.0)\n","Requirement already satisfied: numpy<2.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n","Requirement already satisfied: absl-py>=0.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.3.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.70.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf>=3.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.20.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.32.4)\n","Requirement already satisfied: six>=1.10.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n","Requirement already satisfied: wheel>=0.26 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.45.1)\n","Requirement already satisfied: nvidia-ml-py>=11.450.129 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (13.590.44)\n","Requirement already satisfied: psutil>=5.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (7.2.0)\n","Requirement already satisfied: blessed>=1.17.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (1.25.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.0.12)\n","Requirement already satisfied: typing-extensions>=3.10.0.2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.13.2)\n","Requirement already satisfied: wcwidth>=0.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat) (0.2.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2.0.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2025.11.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard) (2.1.5)\n","Requirement already satisfied: zipp>=3.20 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.20.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.3.1)\n","Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.5.1\n","‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 5:** Patch config cho `main.yml`"],"metadata":{"id":"s9fZ1nW1Igxm"}},{"cell_type":"code","source":["main_cfg = \"configs/main.yml\"\n","import re\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch configs/main.yml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7HN8u1V53hJ","outputId":"dee4b3be-5d74-406b-b92b-8276ef1404da","executionInfo":{"status":"ok","timestamp":1766573382339,"user_tz":-420,"elapsed":17,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ patch configs/main.yml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 6:** Memory fix ·ª©ng v·ªõi t·ª´ng file `<dataset>.yml`"],"metadata":{"id":"pn580tAGIrYT"}},{"cell_type":"code","source":["# Fix OOM cho T4 GPU\n","carla_cfg = \"configs/nerf-gan-carla.yml\"\n","if os.path.exists(carla_cfg):\n","    c = open(carla_cfg,\"r\").read()\n","    # Gi·∫£m t·ª´ 64 xu·ªëng 32 ho·∫∑c 48 ƒë·ªÉ tr√°nh tr√†n VRAM\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 32\")\n","    open(carla_cfg,\"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong {carla_cfg}\")"],"metadata":{"id":"p77GNx76IyOG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766573382352,"user_tz":-420,"elapsed":9,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}},"outputId":"827a758b-c356-4cd7-aaad-6c30f226fd9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong configs/nerf-gan-carla.yml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 7:** X·ª≠ l√Ω ƒë·ªìng lo·∫°t c√°i file `*.yml` chu·∫©n b·ªã cho training"],"metadata":{"id":"aPJz9KxfI9fu"}},{"cell_type":"code","source":["import glob\n","import os\n","import re\n","\n","CONFIG_DIR = \"configs\"\n","config_dir = \"/content/drive/MyDrive/HyperNeRFGAN/configs\"\n","\n","# L·∫•y t·∫•t c·∫£ file trong folder configs\n","files = os.listdir(config_dir)\n","\n","for f in files:\n","    full_path = os.path.join(config_dir, f)\n","\n","    # N·∫øu l√† .yaml -> copy th√™m b·∫£n .yml\n","    if f.endswith(\".yaml\"):\n","        target = full_path.replace(\".yaml\", \".yml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","    # N·∫øu l√† .yml -> copy th√™m b·∫£n .yaml\n","    elif f.endswith(\".yml\"):\n","        target = full_path.replace(\".yml\", \".yaml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","print(\"‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\")\n","\n","# 2. Patch file main.yaml (Set 1 GPU)\n","main_cfg = os.path.join(CONFIG_DIR, \"main.yaml\")\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    # Force 1 GPU\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    # S·ª≠a tham chi·∫øu ƒë·∫øn file config con (c≈©ng ph·∫£i ƒë·ªïi th√†nh yaml n·∫øu c√≥ hardcode)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\")\n","\n","# 3. Patch file dataset config (Fix OOM cho T4 GPU)\n","# T·ª± ƒë·ªông t√¨m file config t∆∞∆°ng ·ª©ng v·ªõi DATASET_NAME\n","target_cfg_name = f\"nerf-gan-{DATASET_NAME.split('_')[0]}\" # Vd: carla_128 -> nerf-gan-carla\n","dataset_cfg = os.path.join(CONFIG_DIR, f\"{target_cfg_name}.yaml\")\n","\n","if os.path.exists(dataset_cfg):\n","    c = open(dataset_cfg, \"r\").read()\n","    # Gi·∫£m th√¥ng s·ªë ƒë·ªÉ v·ª´a v·ªõi 16GB VRAM c·ªßa T4\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 32\")\n","    open(dataset_cfg, \"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong {dataset_cfg}\")\n","else:\n","    print(f\"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y config {dataset_cfg}. C√≥ th·ªÉ t√™n dataset kh√°c v·ªõi quy t·∫Øc ƒë·∫∑t t√™n config.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkfOq_Iy8doi","outputId":"11648f7e-b135-47c2-c5be-941596a21a0a","executionInfo":{"status":"ok","timestamp":1766573382379,"user_tz":-420,"elapsed":25,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\n","‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\n","‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong configs/nerf-gan-carla.yaml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 8:** Ch·∫°y training v·ªõi Ablation `augment_p=0.0` (baseline=0.5)"],"metadata":{"id":"zDfpdi4hJoUR"}},{"cell_type":"code","source":["print(\"üöÄ B·∫Øt ƒë·∫ßu Training...\")\n","\n","\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  python src/infra/launch_local.py hydra.run.dir=. \\\n","  +experiment_name=carla_128_p0 \\\n","  +dataset.name=carla_128 \\\n","  +dataset.root_path={LOCAL_PATH} \\\n","  num_gpus=1 \\\n","  +D_kwargs.patch_size=32 \\\n","  +G_kwargs.synthesis_kwargs.patch_size=32 \\\n","  +G_kwargs.cfg.patch_size=32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW-LiDXf542l","outputId":"bbd9b029-73da-4eae-bfad-77e31ea6ff0e","executionInfo":{"status":"ok","timestamp":1766590827838,"user_tz":-420,"elapsed":17445457,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ B·∫Øt ƒë·∫ßu Training...\n","<=== CONFIG ===>\n","env:\n","  python_bin: python\n","  base_project_dir: ${hydra:runtime.cwd}\n","  before_train_commands: []\n","  torch_extensions_dir: /tmp/torch_extensions\n","  datasets_dir: data\n","  objects_to_copy:\n","  - ${env.base_project_dir}/src\n","  - ${env.base_project_dir}/configs\n","  symlinks_to_create:\n","  - ${env.base_project_dir}/data\n","num_gpus: 1\n","dataset:\n","  source_path: ${env.datasets_dir}/${dataset.name}.zip\n","  target_path: data/${dataset.name}.zip\n","  name: carla_128\n","  root_path: /content/carla_128.zip\n","print_only: false\n","project_release_dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None\n","train_args:\n","  outdir: ${project_release_dir}\n","  data: ${dataset.target_path}\n","  gpus: ${num_gpus}\n","  metrics: fid1k_full\n","  cfg: nerf\n","  generate_video: true\n","  video_front_view: true\n","  snap: 50\n","  aug: fixed\n","  augpipe: crop\n","  p: 0.0\n","  mirror: 1\n","  hydra_cfg_name: nerf-gan-carla.yml\n","train_args_str: --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None\n","  --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True\n","  --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.0 --mirror=1\n","  --hydra_cfg_name=nerf-gan-carla.yml\n","experiment_name: carla_128_p0\n","D_kwargs:\n","  patch_size: 32\n","G_kwargs:\n","  synthesis_kwargs:\n","    patch_size: 32\n","  cfg:\n","    patch_size: 32\n","\n","<=== TRAINING COMMAND ===>\n","\n"," TORCH_EXTENSIONS_DIR=/tmp/torch_extensions python src/train.py --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.0 --mirror=1 --hydra_cfg_name=nerf-gan-carla.yml\n","Dir /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None already exists. Remove it? [y/N]: y\n","y\n","Creating a symlink to /content/drive/MyDrive/HyperNeRFGAN/data, so try not to delete it occasionally!\n","Created a project dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None\n","src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 50,\n","  \"network_snapshot_ticks\": 50,\n","  \"generate_video\": true,\n","  \"video_front_view\": true,\n","  \"metrics\": [\n","    \"fid1k_full\"\n","  ],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"data/carla_128.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 10000,\n","    \"xflip\": true,\n","    \"resolution\": 128\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"patch_size\": 32,\n","    \"channel_max\": 512,\n","    \"channel_base\": 32768,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.NeRFGenerator\",\n","    \"z_dim\": 128,\n","    \"w_dim\": 128,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"synthesis_kwargs\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 32,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"use_normal\": false,\n","      \"theta_std\": 1.0\n","    },\n","    \"cfg\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 32,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"fmm\": {\n","        \"enabled\": true,\n","        \"rank\": 10,\n","        \"activation\": \"demod\"\n","      }\n","    }\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 1.0,\n","    \"style_mixing_prob\": 0.0,\n","    \"pl_weight\": 0\n","  },\n","  \"total_kimg\": 200,\n","  \"batch_size\": 4,\n","  \"batch_gpu\": 4,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": 0.05,\n","  \"augment_p\": 0.0,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"crop\": true,\n","    \"xflip\": 1\n","  },\n","  \"run_dir\": \"/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0-crop\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0-crop\n","Training data:      data/carla_128.zip\n","Training duration:  200 kimg\n","Number of GPUs:     1\n","Number of images:   10000\n","Image resolution:   128\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Num images:  20000\n","Image shape: [3, 128, 128]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\n","NeRFGenerator                   Parameters  Buffers  Input Shape              Output shape      Datatype\n","---                             ---         ---      ---                      ---               ---     \n","mapping.fc0                     16512       -        [4, 128]                 [4, 128]          float32 \n","mapping.fc1                     16512       -        [4, 128]                 [4, 128]          float32 \n","synthesis.pts_linears.0.affine  246390      -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         8192        -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  170280      -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         516         -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis                       -           -        [4, 128]                 [4, 3, 128, 128]  float32 \n","---                             ---         ---      ---                      ---               ---     \n","Total                           1498658     0        -                        -                 -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Input Shape       Output shape      Datatype\n","---            ---         ---      ---               ---               ---     \n","b32.fromrgb    2048        16       [4, 3, 32, 32]    [4, 512, 32, 32]  float16 \n","b32.skip       262144      16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32.conv0      2359808     16       [4, 512, 32, 32]  [4, 512, 32, 32]  float16 \n","b32.conv1      2359808     16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32            -           16       [4, 3, 32, 32]    [4, 512, 16, 16]  float16 \n","b16.skip       262144      16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16.conv0      2359808     16       [4, 512, 16, 16]  [4, 512, 16, 16]  float16 \n","b16.conv1      2359808     16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16            -           16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b8.skip        262144      16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8.conv0       2359808     16       [4, 512, 8, 8]    [4, 512, 8, 8]    float16 \n","b8.conv1       2359808     16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8             -           16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b4.mbstd       -           -        [4, 512, 4, 4]    [4, 513, 4, 4]    float32 \n","b4.conv        2364416     16       [4, 513, 4, 4]    [4, 512, 4, 4]    float32 \n","b4.fc          4194816     -        [4, 8192]         [4, 512]          float32 \n","b4.out         513         -        [4, 512]          [4, 1]            float32 \n","---            ---         ---      ---               ---               ---     \n","Total          21507073    224      -                 -                 -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 200 kimg...\n","\n","tick 0     kimg 0.0      time 7m 17s       sec/tick 1.2     sec/kimg 309.96  maintenance 436.1  cpumem 4.59   gpumem 8.44   augment 0.000\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_p0-None ...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_p0-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","{\"results\": {\"fid1k_full\": 340.18113645303254}, \"metric\": \"fid1k_full\", \"total_time\": 451.3408246040344, \"total_time_str\": \"7m 31s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1766575457.0402334}\n","tick 1     kimg 4.0      time 34m 59s      sec/tick 294.5   sec/kimg 73.63   maintenance 1366.8 cpumem 4.92   gpumem 3.31   augment 0.000\n","tick 2     kimg 8.0      time 39m 48s      sec/tick 289.0   sec/kimg 72.25   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 3     kimg 12.0     time 44m 36s      sec/tick 288.4   sec/kimg 72.10   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 4     kimg 16.0     time 49m 26s      sec/tick 289.3   sec/kimg 72.32   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 5     kimg 20.0     time 54m 19s      sec/tick 293.1   sec/kimg 73.26   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 6     kimg 24.0     time 59m 12s      sec/tick 293.5   sec/kimg 73.36   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 7     kimg 28.0     time 1h 04m 03s   sec/tick 290.8   sec/kimg 72.70   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 8     kimg 32.0     time 1h 08m 51s   sec/tick 287.4   sec/kimg 71.84   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 9     kimg 36.0     time 1h 13m 37s   sec/tick 286.1   sec/kimg 71.53   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 10    kimg 40.0     time 1h 18m 21s   sec/tick 284.1   sec/kimg 71.04   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 11    kimg 44.0     time 1h 23m 08s   sec/tick 287.0   sec/kimg 71.74   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 12    kimg 48.0     time 1h 27m 55s   sec/tick 286.3   sec/kimg 71.58   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 13    kimg 52.0     time 1h 32m 41s   sec/tick 286.4   sec/kimg 71.59   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 14    kimg 56.0     time 1h 37m 33s   sec/tick 292.1   sec/kimg 73.02   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 15    kimg 60.0     time 1h 42m 25s   sec/tick 291.7   sec/kimg 72.91   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 16    kimg 64.0     time 1h 47m 17s   sec/tick 291.7   sec/kimg 72.92   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 17    kimg 68.0     time 1h 52m 10s   sec/tick 292.8   sec/kimg 73.20   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 18    kimg 72.0     time 1h 57m 02s   sec/tick 292.1   sec/kimg 73.03   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 19    kimg 76.0     time 2h 01m 52s   sec/tick 289.8   sec/kimg 72.44   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 20    kimg 80.0     time 2h 06m 34s   sec/tick 282.1   sec/kimg 70.52   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 21    kimg 84.0     time 2h 11m 19s   sec/tick 285.0   sec/kimg 71.25   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 22    kimg 88.0     time 2h 16m 02s   sec/tick 283.0   sec/kimg 70.74   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 23    kimg 92.0     time 2h 20m 44s   sec/tick 282.0   sec/kimg 70.50   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 24    kimg 96.0     time 2h 25m 28s   sec/tick 284.4   sec/kimg 71.10   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 25    kimg 100.0    time 2h 30m 11s   sec/tick 283.0   sec/kimg 70.74   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 26    kimg 104.0    time 2h 34m 58s   sec/tick 286.1   sec/kimg 71.51   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 27    kimg 108.0    time 2h 39m 42s   sec/tick 284.3   sec/kimg 71.08   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 28    kimg 112.0    time 2h 44m 24s   sec/tick 282.0   sec/kimg 70.51   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 29    kimg 116.0    time 2h 49m 08s   sec/tick 283.7   sec/kimg 70.93   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 30    kimg 120.0    time 2h 53m 52s   sec/tick 284.1   sec/kimg 71.02   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 31    kimg 124.0    time 2h 58m 36s   sec/tick 284.1   sec/kimg 71.03   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 32    kimg 128.0    time 3h 03m 20s   sec/tick 283.1   sec/kimg 70.79   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 33    kimg 132.0    time 3h 08m 03s   sec/tick 283.4   sec/kimg 70.85   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 34    kimg 136.0    time 3h 12m 46s   sec/tick 282.7   sec/kimg 70.66   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 35    kimg 140.0    time 3h 17m 30s   sec/tick 284.4   sec/kimg 71.09   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 36    kimg 144.0    time 3h 22m 15s   sec/tick 284.8   sec/kimg 71.19   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 37    kimg 148.0    time 3h 26m 56s   sec/tick 280.3   sec/kimg 70.06   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 38    kimg 152.0    time 3h 31m 38s   sec/tick 282.7   sec/kimg 70.69   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 39    kimg 156.0    time 3h 36m 25s   sec/tick 286.6   sec/kimg 71.66   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 40    kimg 160.0    time 3h 41m 11s   sec/tick 286.0   sec/kimg 71.51   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 41    kimg 164.0    time 3h 45m 54s   sec/tick 282.5   sec/kimg 70.62   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 42    kimg 168.0    time 3h 50m 37s   sec/tick 282.7   sec/kimg 70.68   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 43    kimg 172.0    time 3h 55m 26s   sec/tick 289.0   sec/kimg 72.24   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 44    kimg 176.0    time 4h 00m 15s   sec/tick 288.8   sec/kimg 72.20   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 45    kimg 180.0    time 4h 04m 54s   sec/tick 279.0   sec/kimg 69.76   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 46    kimg 184.0    time 4h 09m 44s   sec/tick 290.5   sec/kimg 72.62   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 47    kimg 188.0    time 4h 14m 34s   sec/tick 289.5   sec/kimg 72.37   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 48    kimg 192.0    time 4h 19m 21s   sec/tick 287.6   sec/kimg 71.91   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 49    kimg 196.0    time 4h 24m 06s   sec/tick 284.3   sec/kimg 71.07   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","tick 50    kimg 200.0    time 4h 28m 49s   sec/tick 283.3   sec/kimg 70.91   maintenance 0.1    cpumem 4.92   gpumem 0.82   augment 0.000\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_p0-None ...\n","{\"results\": {\"fid1k_full\": 154.85067235748454}, \"metric\": \"fid1k_full\", \"total_time\": 270.0676953792572, \"total_time_str\": \"4m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1766590826.1337605}\n","\n","Exiting...\n"]}]}]}