{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **B∆∞·ªõc 1:** Mount Drive v√† Khai b√°o c√°c ƒë∆∞·ªùng d·∫´n"],"metadata":{"id":"dmIxkfqTG5_w"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODg49OX-tRMK","collapsed":true},"outputs":[],"source":["from google.colab import drive\n","import os, shutil\n","\n","if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')"]},{"cell_type":"code","source":["DATASET_NAME = \"carla_128\"\n","ZIP_FILE = f\"{DATASET_NAME}.zip\"\n","DRIVE_PATH = f\"/content/drive/MyDrive/HyperNeRFGAN/data/{ZIP_FILE}\"\n","LOCAL_PATH = f\"/content/{ZIP_FILE}\""],"metadata":{"id":"hVjQhNEDKk0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 2:** Copy dataset xu·ªëng Local (ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω)\n"],"metadata":{"id":"vEhfn8UDHErI"}},{"cell_type":"code","source":["if os.path.exists(DRIVE_PATH):\n","    print(f\"üîÑ ƒêang copy {ZIP_FILE} t·ª´ Drive xu·ªëng Local...\")\n","    shutil.copy(DRIVE_PATH, LOCAL_PATH)\n","    print(f\"‚úÖ ƒê√£ copy xong: {LOCAL_PATH}\")\n","else:\n","    raise FileNotFoundError(f\"‚ùå Kh√¥ng t√¨m th·∫•y file: {DRIVE_PATH}. H√£y ki·ªÉm tra l·∫°i folder data tr√™n Drive.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3yWDXnt5s8V","outputId":"41ed265b-5f78-43d1-cba9-89bb5024ae39","executionInfo":{"status":"ok","timestamp":1766547316950,"user_tz":-420,"elapsed":635,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ ƒêang copy carla_128.zip t·ª´ Drive xu·ªëng Local...\n","‚úÖ ƒê√£ copy xong: /content/carla_128.zip\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 3:** C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Micromamba"],"metadata":{"id":"ep5UCTRXHxD5"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/HyperNeRFGAN\n","\n","# C√†i Micromamba\n","!mkdir -p bin\n","!curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n","!chmod +x bin/micromamba\n","\n","# T·∫°o file environment t·ªëi ∆∞u cho Colab\n","import yaml\n","env_in = \"environment.yaml\"\n","env_out = \"environment_colab.yaml\"\n","\n","# Load environment g·ªëc v√† l·ªçc b·ªè imageio-ffmpeg (c√†i pip sau)\n","if os.path.exists(env_in):\n","    y = yaml.safe_load(open(env_in, \"r\"))\n","    y[\"channels\"] = [\"conda-forge\", \"defaults\"] # B·ªè pytorch channel ƒë·ªÉ c√†i th·ªß c√¥ng\n","    deps = []\n","    for d in y.get(\"dependencies\", []):\n","        if isinstance(d, str) and (d.startswith(\"imageio-ffmpeg\") or d.startswith(\"pytorch\") or d.startswith(\"torchvision\")):\n","            continue\n","        deps.append(d)\n","    y[\"dependencies\"] = deps\n","    with open(env_out, \"w\") as f:\n","        yaml.safe_dump(y, f, sort_keys=False)\n","else:\n","    with open(env_out, \"w\") as f:\n","        f.write(\"channels:\\n  - conda-forge\\ndependencies:\\n  - python=3.8\\n  - pip\\n\")\n","\n","print(\"‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng:\", env_out)\n","\n","# T·∫°o m√¥i tr∆∞·ªùng\n","ENV_PREFIX = \"/content/hypernerfgan_env\"\n","!rm -rf {ENV_PREFIX}\n","!./bin/micromamba create -y -p {ENV_PREFIX} -f environment_colab.yaml\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"H0_0P8E15xzF","outputId":"99ceb036-89ac-41df-ac9d-0839e7380ae1","executionInfo":{"status":"ok","timestamp":1766547376079,"user_tz":-420,"elapsed":59128,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HyperNeRFGAN\n","bin/micromamba\n","‚úÖ ƒê√£ t·∫°o file config m√¥i tr∆∞·ªùng: environment_colab.yaml\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m 'repo.anaconda.com', a commercial channel hosted by Anaconda.com, is used.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m Please make sure you understand Anaconda Terms of Services.\n","    \n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m See: https://legal.anaconda.com/policies/en/\n","\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n","\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n","conda-forge/linux-64  ‚£æ  \n","conda-forge/noarch    ‚£æ  \n","pkgs/main/linux-64    ‚£æ  \n","pkgs/r/linux-64       ‚£æ  \n","pkgs/r/noarch         ‚£æ  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n","conda-forge/linux-64   5%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n","conda-forge/linux-64  24%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n","conda-forge/linux-64  38%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n","conda-forge/linux-64  48%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n","conda-forge/linux-64  61%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n","conda-forge/linux-64  69%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n","conda-forge/linux-64  76%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n","conda-forge/linux-64  81%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n","conda-forge/linux-64  89%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n","conda-forge/linux-64  97%\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                              \n","\u001b[?25h\n","\n","Transaction\n","\n","  Prefix: /content/hypernerfgan_env\n","\n","  Updating specs:\n","\n","   - python=3.8.5\n","   - pip=20.3\n","   - cudatoolkit=10.2\n","   - imageio\n","   - protobuf=3.20.1\n","   - pip\n","\n","\n","  Package                Version  Build                 Channel           Size\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","  Install:\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","  \u001b[32m+ _libgcc_mutex   \u001b[0m         0.1  conda_forge           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ _openmp_mutex   \u001b[0m         4.5  2_gnu                 conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ca-certificates \u001b[0m  2025.11.12  hbd8a1cb_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ cudatoolkit     \u001b[0m     10.2.89  hdec6ad0_13           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ freetype        \u001b[0m      2.12.1  h267a509_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ imageio         \u001b[0m      2.36.0  pyh12aca89_1          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lcms2           \u001b[0m        2.16  hb7c19ff_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ld_impl_linux-64\u001b[0m        2.45  bootstrap_ha15bf96_5  conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ lerc            \u001b[0m       4.0.0  h0aef613_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libblas         \u001b[0m      3.11.0  5_h4a7cf45_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libcblas        \u001b[0m      3.11.0  5_h0358290_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libdeflate      \u001b[0m        1.20  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libffi          \u001b[0m       3.2.1  he1b5a44_1007         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc          \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgcc-ng       \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran     \u001b[0m      15.2.0  h69a702a_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgfortran5    \u001b[0m      15.2.0  h68bc16d_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libgomp         \u001b[0m      15.2.0  he0feb66_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libjpeg-turbo   \u001b[0m       3.1.2  hb03c661_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblapack       \u001b[0m      3.11.0  5_h47877c9_openblas   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma         \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ liblzma-devel   \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libopenblas     \u001b[0m      0.3.30  pthreads_h94d23a6_4   conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libpng          \u001b[0m      1.6.43  h2797004_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libprotobuf     \u001b[0m      3.20.1  h6239696_4            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libsqlite       \u001b[0m      3.46.0  hde9e2c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx       \u001b[0m      15.2.0  h934c35e_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libstdcxx-ng    \u001b[0m      15.2.0  hdf11a46_16           conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libtiff         \u001b[0m       4.6.0  h1dd3fc0_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libwebp-base    \u001b[0m       1.6.0  hd42ef1d_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libxcb          \u001b[0m        1.15  h0b41bf4_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ libzlib         \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ ncurses         \u001b[0m         6.5  h2d0b736_3            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ numpy           \u001b[0m      1.24.4  py38h59b608b_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openjpeg        \u001b[0m       2.5.2  h488ebb8_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ openssl         \u001b[0m      1.1.1w  hd590300_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pillow          \u001b[0m      10.3.0  py38h9e66945_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pip             \u001b[0m      20.3.4  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ protobuf        \u001b[0m      3.20.1  py38hfa26641_0        conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ pthread-stubs   \u001b[0m         0.4  hb9d3cd8_1002         conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python          \u001b[0m       3.8.5  h1103e12_9_cpython    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ python_abi      \u001b[0m         3.8  8_cp38                conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ readline        \u001b[0m         8.3  h853b02a_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ setuptools      \u001b[0m      75.3.0  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ six             \u001b[0m      1.16.0  pyh6c4a22f_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ sqlite          \u001b[0m      3.46.0  h6d4b2fc_0            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ tk              \u001b[0m      8.6.13  noxft_h4845f30_101    conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ wheel           \u001b[0m      0.45.1  pyhd8ed1ab_0          conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxau     \u001b[0m      1.0.12  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xorg-libxdmcp   \u001b[0m       1.1.5  hb03c661_1            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz              \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-gpl-tools    \u001b[0m       5.8.1  hbcc6ac9_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ xz-tools        \u001b[0m       5.8.1  hb9d3cd8_2            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zlib            \u001b[0m      1.2.13  h4ab18f5_6            conda-forge\u001b[32m     Cached\u001b[0m\n","  \u001b[32m+ zstd            \u001b[0m       1.5.6  ha6fb4c9_0            conda-forge\u001b[32m     Cached\u001b[0m\n","\n","  Summary:\n","\n","  Install: 55 packages\n","\n","  Total download: 0 B\n","\n","‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n","\n","\n","\n","Transaction starting\n","\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n","\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking python_abi-3.8-8_cp38\n","Linking ca-certificates-2025.11.12-hbd8a1cb_0\n","Linking libgomp-15.2.0-he0feb66_16\n","Linking _libgcc_mutex-0.1-conda_forge\n","Linking ld_impl_linux-64-2.45-bootstrap_ha15bf96_5\n","Linking _openmp_mutex-4.5-2_gnu\n","Linking libgcc-15.2.0-he0feb66_16\n","Linking libgfortran5-15.2.0-h68bc16d_16\n","Linking ncurses-6.5-h2d0b736_3\n","Linking libjpeg-turbo-3.1.2-hb03c661_0\n","Linking xorg-libxdmcp-1.1.5-hb03c661_1\n","Linking xorg-libxau-1.0.12-hb03c661_1\n","Linking pthread-stubs-0.4-hb9d3cd8_1002\n","Linking libwebp-base-1.6.0-hd42ef1d_0\n","Linking libstdcxx-15.2.0-h934c35e_16\n","Linking libgcc-ng-15.2.0-h69a702a_16\n","Linking liblzma-5.8.1-hb9d3cd8_2\n","Linking libgfortran-15.2.0-h69a702a_16\n","Linking readline-8.3-h853b02a_0\n","Linking lerc-4.0.0-h0aef613_1\n","Linking libstdcxx-ng-15.2.0-hdf11a46_16\n","Linking openssl-1.1.1w-hd590300_0\n","Linking libxcb-1.15-h0b41bf4_0\n","Linking libdeflate-1.20-hd590300_0\n","Linking libzlib-1.2.13-h4ab18f5_6\n","Linking xz-tools-5.8.1-hb9d3cd8_2\n","Linking xz-gpl-tools-5.8.1-hbcc6ac9_2\n","Linking liblzma-devel-5.8.1-hb9d3cd8_2\n","Linking libopenblas-0.3.30-pthreads_h94d23a6_4\n","Linking libffi-3.2.1-he1b5a44_1007\n","Linking cudatoolkit-10.2.89-hdec6ad0_13\n","By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n","\n","Linking libsqlite-3.46.0-hde9e2c9_0\n","Linking zstd-1.5.6-ha6fb4c9_0\n","Linking libpng-1.6.43-h2797004_0\n","Linking tk-8.6.13-noxft_h4845f30_101\n","Linking libprotobuf-3.20.1-h6239696_4\n","Linking zlib-1.2.13-h4ab18f5_6\n","Linking xz-5.8.1-hbcc6ac9_2\n","Linking libblas-3.11.0-5_h4a7cf45_openblas\n","Linking sqlite-3.46.0-h6d4b2fc_0\n","Linking freetype-2.12.1-h267a509_2\n","Linking libtiff-4.6.0-h1dd3fc0_3\n","Linking libcblas-3.11.0-5_h0358290_openblas\n","Linking liblapack-3.11.0-5_h47877c9_openblas\n","Linking python-3.8.5-h1103e12_9_cpython\n","Linking lcms2-2.16-hb7c19ff_0\n","Linking openjpeg-2.5.2-h488ebb8_0\n","Linking wheel-0.45.1-pyhd8ed1ab_0\n","Linking setuptools-75.3.0-pyhd8ed1ab_0\n","Linking pip-20.3.4-pyhd8ed1ab_0\n","Linking six-1.16.0-pyh6c4a22f_0\n","Linking pillow-10.3.0-py38h9e66945_0\n","Linking numpy-1.24.4-py38h59b608b_0\n","Linking protobuf-3.20.1-py38hfa26641_0\n","Linking imageio-2.36.0-pyh12aca89_1\n","\n","Transaction finished\n","\n","\n","To activate this environment, use:\n","\n","    micromamba activate /content/hypernerfgan_env\n","\n","Or to execute a single command in this environment, use:\n","\n","    micromamba run -p /content/hypernerfgan_env mycommand\n","\n","\u001b[33m\u001b[1mwarning  libmamba\u001b[m You are using 'pip' as an additional package manager.\n","    Be aware that packages installed with 'pip' are managed independently from 'conda-forge' channel.\n","\u001b[36m\n","Installing pip packages: hydra-core==1.0.6, click==7.1.2, scipy==1.6.1, ninja==1.10.0, tensorboard==2.4.1, tqdm==4.59.0, gitpython, gpustat, opencv-python, -e .\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 4:** C√†i ƒë·∫∑t Pytorch v√† Dependencies"],"metadata":{"id":"ADOxSyjKIQC9"}},{"cell_type":"code","source":["print(\"‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\")\n","\n","# 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","  --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# 2. C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈© (Quan tr·ªçng)\n","# (Pip 23.3.1 ƒë·ªÉ fix l·ªói omegaconf, Setuptools<59.6 ƒë·ªÉ fix l·ªói distutils)\n","!./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","!./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# 4. C√†i Hydra & Dependencies\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# 5. C√†i c√°c util kh√°c\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja\n","\n","print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n","\n","\n","# # 1. C√†i PyTorch chu·∫©n (CUDA 11.3)\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install torch==1.10.0+cu113 torchvision==0.11.0+cu113 \\\n","#   --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# # 2. QUAN TR·ªåNG: C√†i c·ªë ƒë·ªãnh phi√™n b·∫£n Pip v√† Setuptools c≈©\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install \"pip==23.3.1\" \"setuptools<59.6.0\" wheel\n","\n","# # 3. C√†i repo ·ªü ch·∫ø ƒë·ªô editable\n","# !./bin/micromamba run -p {ENV_PREFIX} pip install -e .\n","\n","# # 4. C√†i Hydra & Dependencies\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install hydra-core==1.0.6 omegaconf==2.0.6 antlr4-python3-runtime==4.8\n","\n","# # 5. C√†i c√°c util kh√°c V√Ä CH·ªêT NUMPY 1.23.5\n","# !./bin/micromamba run -p {ENV_PREFIX} \\\n","#   pip install imageio-ffmpeg opencv-python tensorboard tqdm gpustat gitpython ninja \"numpy==1.23.5\"\n","\n","# print(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXOuH6435y1i","outputId":"7d5dbf40-a636-47f1-f4be-2b13b802e100","collapsed":true,"executionInfo":{"status":"ok","timestamp":1766547563090,"user_tz":-420,"elapsed":187017,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t PyTorch v√† th∆∞ vi·ªán...\n","Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.10.0+cu113\n","  Using cached https://download.pytorch.org/whl/cu113/torch-1.10.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1821.4 MB)\n","Collecting torchvision==0.11.0+cu113\n","  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.11.0%2Bcu113-cp38-cp38-linux_x86_64.whl (21.8 MB)\n","Requirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from torch==1.10.0+cu113) (4.13.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (10.3.0)\n","Requirement already satisfied: numpy in /content/hypernerfgan_env/lib/python3.8/site-packages (from torchvision==0.11.0+cu113) (1.24.4)\n","Installing collected packages: torch, torchvision\n","Successfully installed torch-1.10.0+cu113 torchvision-0.11.0+cu113\n","Collecting pip==23.3.1\n","  Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n","Collecting setuptools<59.6.0\n","  Using cached setuptools-59.5.0-py3-none-any.whl (952 kB)\n","Requirement already satisfied: wheel in /content/hypernerfgan_env/lib/python3.8/site-packages (0.45.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 75.3.0\n","    Uninstalling setuptools-75.3.0:\n","      Successfully uninstalled setuptools-75.3.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.3.4\n","    Uninstalling pip-20.3.4:\n","      Successfully uninstalled pip-20.3.4\n","Successfully installed pip-23.3.1 setuptools-59.5.0\n","Obtaining file:///content/drive/MyDrive/HyperNeRFGAN\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: inr-gan\n","  Attempting uninstall: inr-gan\n","    Found existing installation: inr_gan 0.0.1\n","    Uninstalling inr_gan-0.0.1:\n","      Successfully uninstalled inr_gan-0.0.1\n","  Running setup.py develop for inr-gan\n","Successfully installed inr-gan-0.0.1\n","Requirement already satisfied: hydra-core==1.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (1.0.6)\n","Requirement already satisfied: omegaconf==2.0.6 in /content/hypernerfgan_env/lib/python3.8/site-packages (2.0.6)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (4.8)\n","Requirement already satisfied: importlib-resources in /content/hypernerfgan_env/lib/python3.8/site-packages (from hydra-core==1.0.6) (6.4.5)\n","Requirement already satisfied: PyYAML>=5.1.* in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (6.0.3)\n","Requirement already satisfied: typing-extensions in /content/hypernerfgan_env/lib/python3.8/site-packages (from omegaconf==2.0.6) (4.13.2)\n","Requirement already satisfied: zipp>=3.1.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-resources->hydra-core==1.0.6) (3.20.2)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mCollecting imageio-ffmpeg\n","  Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: opencv-python in /content/hypernerfgan_env/lib/python3.8/site-packages (4.12.0.88)\n","Requirement already satisfied: tensorboard in /content/hypernerfgan_env/lib/python3.8/site-packages (2.4.1)\n","Requirement already satisfied: tqdm in /content/hypernerfgan_env/lib/python3.8/site-packages (4.59.0)\n","Requirement already satisfied: gpustat in /content/hypernerfgan_env/lib/python3.8/site-packages (1.1.1)\n","Requirement already satisfied: gitpython in /content/hypernerfgan_env/lib/python3.8/site-packages (3.1.45)\n","Requirement already satisfied: ninja in /content/hypernerfgan_env/lib/python3.8/site-packages (1.10.0)\n","Requirement already satisfied: setuptools in /content/hypernerfgan_env/lib/python3.8/site-packages (from imageio-ffmpeg) (59.5.0)\n","Requirement already satisfied: numpy<2.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n","Requirement already satisfied: absl-py>=0.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.3.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.70.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.7)\n","Requirement already satisfied: protobuf>=3.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.20.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (2.32.4)\n","Requirement already satisfied: six>=1.10.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (3.0.6)\n","Requirement already satisfied: wheel>=0.26 in /content/hypernerfgan_env/lib/python3.8/site-packages (from tensorboard) (0.45.1)\n","Requirement already satisfied: nvidia-ml-py>=11.450.129 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (13.590.44)\n","Requirement already satisfied: psutil>=5.6.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (7.2.0)\n","Requirement already satisfied: blessed>=1.17.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gpustat) (1.25.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.0.12)\n","Requirement already satisfied: typing-extensions>=3.10.0.2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitpython) (4.13.2)\n","Requirement already satisfied: wcwidth>=0.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat) (0.2.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.9.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2.0.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /content/hypernerfgan_env/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard) (8.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard) (2025.11.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard) (2.1.5)\n","Requirement already satisfied: zipp>=3.20 in /content/hypernerfgan_env/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.20.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /content/hypernerfgan_env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.6.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /content/hypernerfgan_env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.3.1)\n","Using cached imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: imageio-ffmpeg\n","Successfully installed imageio-ffmpeg-0.5.1\n","‚úÖ ƒê√£ c√†i ƒë·∫∑t xong m√¥i tr∆∞·ªùng (Dependencies OK).\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 5:** Patch config cho `main.yml`"],"metadata":{"id":"s9fZ1nW1Igxm"}},{"cell_type":"code","source":["main_cfg = \"configs/main.yml\"\n","import re\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch configs/main.yml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7HN8u1V53hJ","outputId":"80cd176f-b85f-4cc8-b5c1-a3e351b4a97a","executionInfo":{"status":"ok","timestamp":1766547563557,"user_tz":-420,"elapsed":465,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ patch configs/main.yml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 6:** Memory fix ·ª©ng v·ªõi t·ª´ng file `<dataset>.yml`"],"metadata":{"id":"pn580tAGIrYT"}},{"cell_type":"code","source":["# Fix OOM cho T4 GPU\n","carla_cfg = \"configs/nerf-gan-carla.yml\"\n","if os.path.exists(carla_cfg):\n","    c = open(carla_cfg,\"r\").read()\n","    # Gi·∫£m t·ª´ 64 xu·ªëng 32 ho·∫∑c 48 ƒë·ªÉ tr√°nh tr√†n VRAM\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 8\")\n","    open(carla_cfg,\"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong {carla_cfg}\")"],"metadata":{"id":"p77GNx76IyOG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766547563881,"user_tz":-420,"elapsed":297,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}},"outputId":"eb0f738f-3938-4725-eebc-c8e43ad33f52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ gi·∫£m c·∫•u h√¨nh memory trong configs/nerf-gan-carla.yml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 7:** X·ª≠ l√Ω ƒë·ªìng lo·∫°t c√°i file `*.yml` chu·∫©n b·ªã cho training"],"metadata":{"id":"aPJz9KxfI9fu"}},{"cell_type":"code","source":["import glob\n","import os\n","import re\n","\n","CONFIG_DIR = \"configs\"\n","config_dir = \"/content/drive/MyDrive/HyperNeRFGAN/configs\"\n","\n","# L·∫•y t·∫•t c·∫£ file trong folder configs\n","files = os.listdir(config_dir)\n","\n","for f in files:\n","    full_path = os.path.join(config_dir, f)\n","\n","    # N·∫øu l√† .yaml -> copy th√™m b·∫£n .yml\n","    if f.endswith(\".yaml\"):\n","        target = full_path.replace(\".yaml\", \".yml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","    # N·∫øu l√† .yml -> copy th√™m b·∫£n .yaml\n","    elif f.endswith(\".yml\"):\n","        target = full_path.replace(\".yml\", \".yaml\")\n","        if not os.path.exists(target):\n","            shutil.copy(full_path, target)\n","            print(f\"   Created clone: {os.path.basename(target)}\")\n","\n","print(\"‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\")\n","\n","# 2. Patch file main.yaml (Set 1 GPU)\n","main_cfg = os.path.join(CONFIG_DIR, \"main.yaml\")\n","if os.path.exists(main_cfg):\n","    txt = open(main_cfg, \"r\").read()\n","    # Force 1 GPU\n","    txt = re.sub(r\"^num_gpus:\\s*\\d+.*$\", \"num_gpus: 1\", txt, flags=re.M)\n","    # S·ª≠a tham chi·∫øu ƒë·∫øn file config con (c≈©ng ph·∫£i ƒë·ªïi th√†nh yaml n·∫øu c√≥ hardcode)\n","    open(main_cfg, \"w\").write(txt)\n","    print(\"‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\")\n","\n","# 3. Patch file dataset config (Fix OOM cho T4 GPU)\n","# T·ª± ƒë·ªông t√¨m file config t∆∞∆°ng ·ª©ng v·ªõi DATASET_NAME\n","target_cfg_name = f\"nerf-gan-{DATASET_NAME.split('_')[0]}\" # Vd: carla_128 -> nerf-gan-carla\n","dataset_cfg = os.path.join(CONFIG_DIR, f\"{target_cfg_name}.yaml\")\n","\n","if os.path.exists(dataset_cfg):\n","    c = open(dataset_cfg, \"r\").read()\n","    # Gi·∫£m th√¥ng s·ªë ƒë·ªÉ v·ª´a v·ªõi 16GB VRAM c·ªßa T4\n","    c = c.replace(\"patch_size: 64\", \"patch_size: 32\")\n","    c = c.replace(\"n_samples: 64\", \"n_samples: 8\")\n","    open(dataset_cfg, \"w\").write(c)\n","    print(f\"‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong {dataset_cfg}\")\n","else:\n","    print(f\"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y config {dataset_cfg}. C√≥ th·ªÉ t√™n dataset kh√°c v·ªõi quy t·∫Øc ƒë·∫∑t t√™n config.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KkfOq_Iy8doi","outputId":"ac4cbc53-8dcf-4594-d077-4a8a649e7a72","executionInfo":{"status":"ok","timestamp":1766547563924,"user_tz":-420,"elapsed":41,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Created clone: main.yaml\n","   Created clone: nerf-gan-carla.yaml\n","‚úÖ Configs ƒë√£ s·∫µn s√†ng (Dual extension).\n","‚úÖ ƒê√£ patch main.yaml (num_gpus=1)\n","‚úÖ ƒê√£ t·ªëi ∆∞u b·ªô nh·ªõ trong configs/nerf-gan-carla.yaml\n"]}]},{"cell_type":"markdown","source":["# **B∆∞·ªõc 8:** Ch·∫°y training v·ªõi Ablation `n_samples=8` trong NeRF renderer (baseline=32)\n"],"metadata":{"id":"zDfpdi4hJoUR"}},{"cell_type":"code","source":["print(\"üöÄ B·∫Øt ƒë·∫ßu Training...\")\n","\n","\n","!./bin/micromamba run -p {ENV_PREFIX} \\\n","  python src/infra/launch_local.py hydra.run.dir=. \\\n","  +experiment_name=carla_128_ns8 \\\n","  +dataset.name=carla_128 \\\n","  +dataset.root_path={LOCAL_PATH} \\\n","  num_gpus=1 \\\n","  +D_kwargs.patch_size=32 \\\n","  +G_kwargs.synthesis_kwargs.patch_size=32 \\\n","  +G_kwargs.cfg.patch_size=32 \\\n","  +G_kwargs.synthesis_kwargs.n_samples=8 \\\n","  +G_kwargs.cfg.n_samples=8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW-LiDXf542l","outputId":"aa25e0e7-9321-4674-a1ad-3e80c9a9fcfa","executionInfo":{"status":"ok","timestamp":1766560481260,"user_tz":-420,"elapsed":12917335,"user":{"displayName":"Hai-Dang Nguyen","userId":"05456720290253066202"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ B·∫Øt ƒë·∫ßu Training...\n","<=== CONFIG ===>\n","env:\n","  python_bin: python\n","  base_project_dir: ${hydra:runtime.cwd}\n","  before_train_commands: []\n","  torch_extensions_dir: /tmp/torch_extensions\n","  datasets_dir: data\n","  objects_to_copy:\n","  - ${env.base_project_dir}/src\n","  - ${env.base_project_dir}/configs\n","  symlinks_to_create:\n","  - ${env.base_project_dir}/data\n","num_gpus: 1\n","dataset:\n","  source_path: ${env.datasets_dir}/${dataset.name}.zip\n","  target_path: data/${dataset.name}.zip\n","  name: carla_128\n","  root_path: /content/carla_128.zip\n","print_only: false\n","project_release_dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None\n","train_args:\n","  outdir: ${project_release_dir}\n","  data: ${dataset.target_path}\n","  gpus: ${num_gpus}\n","  metrics: fid1k_full\n","  cfg: nerf\n","  generate_video: true\n","  video_front_view: true\n","  snap: 50\n","  aug: fixed\n","  augpipe: crop\n","  p: 0.5\n","  mirror: 1\n","  hydra_cfg_name: nerf-gan-carla.yml\n","train_args_str: --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None\n","  --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True\n","  --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.5 --mirror=1\n","  --hydra_cfg_name=nerf-gan-carla.yml\n","experiment_name: carla_128_ns8\n","D_kwargs:\n","  patch_size: 32\n","G_kwargs:\n","  synthesis_kwargs:\n","    patch_size: 32\n","    n_samples: 8\n","  cfg:\n","    patch_size: 32\n","    n_samples: 8\n","\n","<=== TRAINING COMMAND ===>\n","\n"," TORCH_EXTENSIONS_DIR=/tmp/torch_extensions python src/train.py --outdir=/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None --data=data/carla_128.zip --gpus=1 --metrics=fid1k_full --cfg=nerf --generate_video=True --video_front_view=True --snap=50 --aug=fixed --augpipe=crop --p=0.5 --mirror=1 --hydra_cfg_name=nerf-gan-carla.yml\n","Dir /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None already exists. Remove it? [y/N]: y\n","Creating a symlink to /content/drive/MyDrive/HyperNeRFGAN/data, so try not to delete it occasionally!\n","Created a project dir: /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None\n","src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Training options:\n","{\n","  \"num_gpus\": 1,\n","  \"image_snapshot_ticks\": 50,\n","  \"network_snapshot_ticks\": 50,\n","  \"generate_video\": true,\n","  \"video_front_view\": true,\n","  \"metrics\": [\n","    \"fid1k_full\"\n","  ],\n","  \"random_seed\": 0,\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"data/carla_128.zip\",\n","    \"use_labels\": false,\n","    \"max_size\": 10000,\n","    \"xflip\": true,\n","    \"resolution\": 128\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"num_workers\": 3,\n","    \"prefetch_factor\": 2\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks.Discriminator\",\n","    \"block_kwargs\": {},\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 4\n","    },\n","    \"patch_size\": 32,\n","    \"channel_max\": 512,\n","    \"channel_base\": 32768,\n","    \"num_fp16_res\": 4,\n","    \"conv_clamp\": 256\n","  },\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks.NeRFGenerator\",\n","    \"z_dim\": 128,\n","    \"w_dim\": 128,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"synthesis_kwargs\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 8,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"use_normal\": false,\n","      \"theta_std\": 1.0\n","    },\n","    \"cfg\": {\n","      \"width\": 128,\n","      \"num_layers\": 4,\n","      \"perturb\": 1.0,\n","      \"raw_noise_std\": 1.0,\n","      \"n_samples\": 8,\n","      \"n_importance\": 0,\n","      \"white_bkgd\": true,\n","      \"patch_size\": 32,\n","      \"phi_low\": -90,\n","      \"phi_high\": 0,\n","      \"theta_low\": -180,\n","      \"theta_high\": 180,\n","      \"render_size\": 2.0,\n","      \"shift\": -0.3,\n","      \"fmm\": {\n","        \"enabled\": true,\n","        \"rank\": 10,\n","        \"activation\": \"demod\"\n","      }\n","    }\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"lr\": 0.0025,\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 1.0,\n","    \"style_mixing_prob\": 0.0,\n","    \"pl_weight\": 0\n","  },\n","  \"total_kimg\": 200,\n","  \"batch_size\": 4,\n","  \"batch_gpu\": 4,\n","  \"ema_kimg\": 20,\n","  \"ema_rampup\": 0.05,\n","  \"augment_p\": 0.5,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"crop\": true,\n","    \"xflip\": 1\n","  },\n","  \"run_dir\": \"/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0.5-crop\"\n","}\n","\n","Output directory:   /content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/00000-carla_128-mirror-nerf-r1_gamma1-fixed-p0.5-crop\n","Training data:      data/carla_128.zip\n","Training duration:  200 kimg\n","Number of GPUs:     1\n","Number of images:   10000\n","Image resolution:   128\n","Conditional model:  False\n","Dataset x-flips:    True\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","\n","Num images:  20000\n","Image shape: [3, 128, 128]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\n","NeRFGenerator                   Parameters  Buffers  Input Shape              Output shape      Datatype\n","---                             ---         ---      ---                      ---               ---     \n","mapping.fc0                     16512       -        [4, 128]                 [4, 128]          float32 \n","mapping.fc1                     16512       -        [4, 128]                 [4, 128]          float32 \n","synthesis.pts_linears.0.affine  246390      -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         8192        -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  330240      -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         16512       -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  170280      -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         516         -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis.pts_linears.0.affine  -           -        [1, 128]                 [1, 1910]         float32 \n","synthesis.pts_linears.0         -           -        [32768, 63] + [1, 128]   [32768, 128]      float32 \n","synthesis.pts_linears.1.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.1         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.2.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.2         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.pts_linears.3.affine  -           -        [1, 128]                 [1, 2560]         float32 \n","synthesis.pts_linears.3         -           -        [32768, 128] + [1, 128]  [32768, 128]      float32 \n","synthesis.output_linear.affine  -           -        [1, 128]                 [1, 1320]         float32 \n","synthesis.output_linear         -           -        [32768, 128] + [1, 128]  [32768, 4]        float32 \n","synthesis                       -           -        [4, 128]                 [4, 3, 128, 128]  float32 \n","---                             ---         ---      ---                      ---               ---     \n","Total                           1498658     0        -                        -                 -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Input Shape       Output shape      Datatype\n","---            ---         ---      ---               ---               ---     \n","b32.fromrgb    2048        16       [4, 3, 32, 32]    [4, 512, 32, 32]  float16 \n","b32.skip       262144      16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32.conv0      2359808     16       [4, 512, 32, 32]  [4, 512, 32, 32]  float16 \n","b32.conv1      2359808     16       [4, 512, 32, 32]  [4, 512, 16, 16]  float16 \n","b32            -           16       [4, 3, 32, 32]    [4, 512, 16, 16]  float16 \n","b16.skip       262144      16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16.conv0      2359808     16       [4, 512, 16, 16]  [4, 512, 16, 16]  float16 \n","b16.conv1      2359808     16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b16            -           16       [4, 512, 16, 16]  [4, 512, 8, 8]    float16 \n","b8.skip        262144      16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8.conv0       2359808     16       [4, 512, 8, 8]    [4, 512, 8, 8]    float16 \n","b8.conv1       2359808     16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b8             -           16       [4, 512, 8, 8]    [4, 512, 4, 4]    float16 \n","b4.mbstd       -           -        [4, 512, 4, 4]    [4, 513, 4, 4]    float32 \n","b4.conv        2364416     16       [4, 513, 4, 4]    [4, 512, 4, 4]    float32 \n","b4.fc          4194816     -        [4, 8192]         [4, 512]          float32 \n","b4.out         513         -        [4, 512]          [4, 1]            float32 \n","---            ---         ---      ---               ---               ---     \n","Total          21507073    224      -                 -                 -       \n","\n","Setting up augmentation...\n","Distributing across 1 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","Training for 200 kimg...\n","\n","tick 0     kimg 0.0      time 1m 45s       sec/tick 1.2     sec/kimg 300.97  maintenance 103.9  cpumem 4.70   gpumem 8.44   augment 0.500\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_ns8-None ...\n","/content/hypernerfgan_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:40: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"bool\"):\n","/content/drive/MyDrive/HyperNeRFGAN/experiments/carla_128_ns8-None/src/train.py:42: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n","  if not hasattr(np, \"object\"):\n","{\"results\": {\"fid1k_full\": 342.1218687617419}, \"metric\": \"fid1k_full\", \"total_time\": 175.02692770957947, \"total_time_str\": \"2m 55s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1766548273.7049122}\n","tick 1     kimg 4.0      time 12m 39s      sec/tick 251.3   sec/kimg 62.81   maintenance 402.4  cpumem 4.97   gpumem 3.31   augment 0.500\n","tick 2     kimg 8.0      time 16m 48s      sec/tick 248.7   sec/kimg 62.16   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 3     kimg 12.0     time 20m 58s      sec/tick 249.9   sec/kimg 62.48   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 4     kimg 16.0     time 25m 07s      sec/tick 249.5   sec/kimg 62.37   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 5     kimg 20.0     time 29m 17s      sec/tick 249.4   sec/kimg 62.36   maintenance 0.2    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 6     kimg 24.0     time 33m 21s      sec/tick 243.9   sec/kimg 60.98   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 7     kimg 28.0     time 37m 27s      sec/tick 245.6   sec/kimg 61.40   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 8     kimg 32.0     time 41m 33s      sec/tick 246.8   sec/kimg 61.69   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 9     kimg 36.0     time 45m 46s      sec/tick 252.9   sec/kimg 63.23   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 10    kimg 40.0     time 49m 54s      sec/tick 247.6   sec/kimg 61.90   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 11    kimg 44.0     time 53m 58s      sec/tick 244.2   sec/kimg 61.06   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 12    kimg 48.0     time 58m 06s      sec/tick 247.2   sec/kimg 61.81   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 13    kimg 52.0     time 1h 02m 13s   sec/tick 247.4   sec/kimg 61.84   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 14    kimg 56.0     time 1h 06m 27s   sec/tick 253.8   sec/kimg 63.45   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 15    kimg 60.0     time 1h 10m 39s   sec/tick 251.2   sec/kimg 62.80   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 16    kimg 64.0     time 1h 14m 46s   sec/tick 247.9   sec/kimg 61.96   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 17    kimg 68.0     time 1h 19m 03s   sec/tick 256.6   sec/kimg 64.15   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 18    kimg 72.0     time 1h 23m 15s   sec/tick 251.3   sec/kimg 62.81   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 19    kimg 76.0     time 1h 27m 21s   sec/tick 246.3   sec/kimg 61.58   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 20    kimg 80.0     time 1h 31m 28s   sec/tick 246.8   sec/kimg 61.70   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 21    kimg 84.0     time 1h 35m 34s   sec/tick 246.0   sec/kimg 61.50   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 22    kimg 88.0     time 1h 39m 48s   sec/tick 254.1   sec/kimg 63.53   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 23    kimg 92.0     time 1h 43m 54s   sec/tick 246.0   sec/kimg 61.50   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 24    kimg 96.0     time 1h 47m 56s   sec/tick 241.7   sec/kimg 60.42   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 25    kimg 100.0    time 1h 52m 04s   sec/tick 247.2   sec/kimg 61.80   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 26    kimg 104.0    time 1h 56m 08s   sec/tick 243.9   sec/kimg 60.98   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 27    kimg 108.0    time 2h 00m 26s   sec/tick 258.2   sec/kimg 64.55   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 28    kimg 112.0    time 2h 04m 23s   sec/tick 237.4   sec/kimg 59.36   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 29    kimg 116.0    time 2h 08m 18s   sec/tick 234.9   sec/kimg 58.74   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 30    kimg 120.0    time 2h 12m 14s   sec/tick 235.6   sec/kimg 58.89   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 31    kimg 124.0    time 2h 16m 11s   sec/tick 236.3   sec/kimg 59.08   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 32    kimg 128.0    time 2h 20m 06s   sec/tick 235.6   sec/kimg 58.90   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 33    kimg 132.0    time 2h 24m 00s   sec/tick 233.3   sec/kimg 58.33   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 34    kimg 136.0    time 2h 27m 52s   sec/tick 232.1   sec/kimg 58.01   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 35    kimg 140.0    time 2h 31m 47s   sec/tick 235.1   sec/kimg 58.79   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 36    kimg 144.0    time 2h 35m 41s   sec/tick 233.9   sec/kimg 58.47   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 37    kimg 148.0    time 2h 39m 34s   sec/tick 232.5   sec/kimg 58.13   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 38    kimg 152.0    time 2h 43m 19s   sec/tick 225.3   sec/kimg 56.32   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 39    kimg 156.0    time 2h 47m 07s   sec/tick 228.2   sec/kimg 57.05   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 40    kimg 160.0    time 2h 50m 56s   sec/tick 228.8   sec/kimg 57.19   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 41    kimg 164.0    time 2h 54m 37s   sec/tick 220.3   sec/kimg 55.07   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 42    kimg 168.0    time 2h 58m 24s   sec/tick 226.9   sec/kimg 56.72   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 43    kimg 172.0    time 3h 02m 10s   sec/tick 225.6   sec/kimg 56.41   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 44    kimg 176.0    time 3h 05m 56s   sec/tick 226.4   sec/kimg 56.61   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 45    kimg 180.0    time 3h 09m 41s   sec/tick 225.1   sec/kimg 56.26   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 46    kimg 184.0    time 3h 13m 25s   sec/tick 224.0   sec/kimg 56.01   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 47    kimg 188.0    time 3h 17m 10s   sec/tick 224.8   sec/kimg 56.21   maintenance 0.2    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 48    kimg 192.0    time 3h 20m 36s   sec/tick 205.4   sec/kimg 51.36   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 49    kimg 196.0    time 3h 24m 01s   sec/tick 204.6   sec/kimg 51.16   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","tick 50    kimg 200.0    time 3h 27m 22s   sec/tick 201.5   sec/kimg 50.42   maintenance 0.1    cpumem 4.97   gpumem 0.61   augment 0.500\n","Exporting sample video...\n","Done rendering\n","Done rendering\n","Evaluating metrics for carla_128_ns8-None ...\n","{\"results\": {\"fid1k_full\": 260.0901929589578}, \"metric\": \"fid1k_full\", \"total_time\": 86.84623718261719, \"total_time_str\": \"1m 27s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1766560479.7053134}\n","\n","Exiting...\n"]}]}]}